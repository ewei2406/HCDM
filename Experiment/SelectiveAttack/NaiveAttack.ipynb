{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Environment ====\n",
      "  torch version: 1.10.2\n",
      "  device: cpu\n",
      "  torch seed: 123\n",
      "==== Dataset: cora ====\n",
      "Loading cora dataset...\n",
      "\n",
      "[i] Dataset Summary: \n",
      "\tadj shape: [2708, 2708]\n",
      "\tfeature shape: [2708, 1433]\n",
      "\tnum labels: 7\n",
      "\tsplit seed: 123\n",
      "\ttrain|val|test: 140|500|1000\n",
      "Number of protected nodes: 285\n",
      "Protected Size: 10.52%\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join('../..'))\n",
    "\n",
    "################################################\n",
    "# Arguments\n",
    "################################################\n",
    "\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--seed', type=int, default=123, help='Random seed for model')\n",
    "\n",
    "parser.add_argument('--model_lr', type=float, default=0.01, help='Initial learning rate')\n",
    "parser.add_argument('--weight_decay', type=float, default=5e-4, help='Weight decay (L2 loss on parameters)')\n",
    "parser.add_argument('--hidden_layers', type=int, default=32, help='Number of hidden layers')\n",
    "parser.add_argument('--dropout', type=float, default=0.5, help='Dropout rate for GCN')\n",
    "\n",
    "parser.add_argument('--protect_size', type=float, default=0.1, help='Number of randomly chosen protected nodes')\n",
    "parser.add_argument('--ptb_rate', type=float, default=0.25, help='Perturbation rate (percentage of available edges)')\n",
    "\n",
    "parser.add_argument('--do_sampling', type=str, default='Y', help='to do sampling or not')\n",
    "parser.add_argument('--sample_size', type=int, default=500, help='')\n",
    "parser.add_argument('--num_samples', type=int, default=20, help='')\n",
    "\n",
    "\n",
    "parser.add_argument('--reg_epochs', type=int, default=100, help='Epochs to train models')\n",
    "parser.add_argument('--ptb_epochs', type=int, default=30, help='Epochs to perturb adj matrix')\n",
    "parser.add_argument('--surrogate_epochs', type=int, default=0, help='Epochs to train surrogate before perturb')\n",
    "\n",
    "parser.add_argument('--save', type=str, default='N', help='save the outputs to csv')\n",
    "parser.add_argument('--save_location', type=str, default=\"./SelectiveAttack.csv\", help='where to save the outputs to csv')\n",
    "parser.add_argument('--dataset', type=str, default='cora', help='dataset')\n",
    "\n",
    "\n",
    "parser.add_argument('--check_universal', type=str, default='N', help='check universal protection')\n",
    "\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "################################################\n",
    "# Environment\n",
    "################################################\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "if device != 'cpu':\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "print('==== Environment ====')\n",
    "print(f'  torch version: {torch.__version__}')\n",
    "print(f'  device: {device}')\n",
    "print(f'  torch seed: {args.seed}')\n",
    "\n",
    "################################################\n",
    "# Dataset\n",
    "################################################\n",
    "\n",
    "from Utils import GraphData\n",
    "\n",
    "print(f'==== Dataset: {args.dataset} ====')\n",
    "\n",
    "graph = GraphData.getGraph(\"../../Datasets\", args.dataset, \"gcn\", args.seed, device)\n",
    "graph.summarize()\n",
    "\n",
    "################################################\n",
    "# Designate protected\n",
    "################################################\n",
    "\n",
    "g0 = torch.rand(graph.features.shape[0]) <= args.protect_size\n",
    "# g0 = graph.labels == 5 \n",
    "g0 = g0.to(device)\n",
    "gX = ~g0\n",
    "\n",
    "print(f\"Number of protected nodes: {g0.sum():.0f}\")\n",
    "print(f\"Protected Size: {g0.sum() / graph.features.shape[0]:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  ..., False, False, False])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "# Generate Perturbations (RANDOM NOISE)\n",
    "################################################\n",
    "import Utils.Utils as Utils\n",
    "import torch.nn.functional as F\n",
    "\n",
    "noise = torch.zeros_like(graph.adj)\n",
    "noise.index_fill_(0, Utils.bool_to_idx(gX).squeeze(), 1)\n",
    "noise.index_fill_(1, Utils.bool_to_idx(gX).squeeze(), 1)\n",
    "noise = torch.ones_like(noise) - noise\n",
    "noise = noise * (graph.adj.sum() * args.ptb_rate / noise.sum())\n",
    "best = torch.bernoulli(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2639.)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.adj.sum() * args.ptb_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training baseline: 100%|██████████| 100/100 [00:07<00:00, 13.56it/s, loss=0.02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G0: 72.28%\n",
      "GX: 78.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training locked: 100%|██████████| 100/100 [00:06<00:00, 14.52it/s, loss=0.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G0: 47.37%\n",
      "GX: 74.16%\n",
      "==== Accuracies ====\n",
      "         ΔG0\tΔGX\n",
      "task1 | -24.9%\t-4.0%\n",
      "     Within G0 ====\n",
      "                A-A\tA-B\tTOTAL\n",
      "          (+)   208  \t1121  \t1329\n",
      "          (-)   1  \t0  \t1\n",
      "     Within GX ====\n",
      "                A-A\tA-B\tTOTAL\n",
      "          (+)   0  \t0  \t0\n",
      "          (-)   0  \t0  \t0\n",
      "     Between G0-GX ====\n",
      "                A-A\tA-B\tTOTAL\n",
      "          (+)   0  \t0  \t0\n",
      "          (-)   0  \t0  \t0\n",
      "\n",
      "        TOTAL   209  \t1121  \t1330\n",
      "{'g0': {'add': {'same': 208, 'diff': 1121, 'total': 1329}, 'remove': {'same': 1, 'diff': 0, 'total': 1}, 'total': 1330}, 'gX': {'add': {'same': 0, 'diff': 0, 'total': 0}, 'remove': {'same': 0, 'diff': 0, 'total': 0}, 'total': 0}, 'g0gX': {'add': {'same': 0, 'diff': 0, 'total': 0}, 'remove': {'same': 0, 'diff': 0, 'total': 0}, 'total': 0}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "################################################\n",
    "# Evaluation\n",
    "################################################\n",
    "from Models.GCN import GCN\n",
    "import Utils.Metrics as Metrics\n",
    "\n",
    "baseline_model = GCN(\n",
    "    input_features=graph.features.shape[1],\n",
    "    output_classes=graph.labels.max().item()+1,\n",
    "    hidden_layers=args.hidden_layers,\n",
    "    device=device,\n",
    "    lr=args.model_lr,\n",
    "    dropout=args.dropout,\n",
    "    weight_decay=args.weight_decay,\n",
    "    name=f\"baseline\"\n",
    ").to(device)\n",
    "\n",
    "baseline_model.fit(graph, args.reg_epochs)\n",
    "\n",
    "pred = baseline_model(graph.features, graph.adj)\n",
    "baseline_acc = Metrics.partial_acc(pred, graph.labels, g0, gX)\n",
    "\n",
    "locked_adj = Utils.get_modified_adj(graph.adj, best)\n",
    "\n",
    "locked_model = GCN(\n",
    "    input_features=graph.features.shape[1],\n",
    "    output_classes=graph.labels.max().item()+1,\n",
    "    hidden_layers=args.hidden_layers,\n",
    "    device=device,\n",
    "    lr=args.model_lr,\n",
    "    dropout=args.dropout,\n",
    "    weight_decay=args.weight_decay,\n",
    "    name=f\"locked\"\n",
    ")\n",
    "\n",
    "locked_model.fitManual(graph.features, locked_adj, graph.labels, graph.idx_train, graph.idx_test, args.reg_epochs)\n",
    "\n",
    "pred = locked_model(graph.features, locked_adj)\n",
    "locked_acc = Metrics.partial_acc(pred, graph.labels, g0, gX)\n",
    "\n",
    "################################################\n",
    "# Summarize\n",
    "################################################\n",
    "\n",
    "dg0 = locked_acc[\"g0\"] - baseline_acc[\"g0\"]\n",
    "dgX = locked_acc[\"gX\"] - baseline_acc[\"gX\"]\n",
    "\n",
    "print(\"==== Accuracies ====\")\n",
    "print(f\"         ΔG0\\tΔGX\")\n",
    "print(f\"task1 | {dg0:.1%}\\t{dgX:.1%}\")\n",
    "\n",
    "diff = locked_adj - graph.adj\n",
    "diffSummary = Metrics.show_metrics(diff, graph.labels, g0, device)\n",
    "\n",
    "print(diffSummary)\n",
    "\n",
    "################################################\n",
    "# Check universal protection\n",
    "################################################\n",
    "\n",
    "if (args.check_universal == \"Y\"):\n",
    "    import Utils.Export as Export\n",
    "    from datetime import datetime\n",
    "\n",
    "    universalResults = {\n",
    "        \"date\": datetime.today().strftime('%Y-%m-%d-%H:%M:%S'),\n",
    "        \"seed\": args.seed,\n",
    "        \"dataset\": args.dataset,\n",
    "        \"protect_size\": args.protect_size,\n",
    "        \"reg_epochs\": args.reg_epochs,\n",
    "        \"ptb_epochs\": args.ptb_epochs,\n",
    "        \"ptb_rate\": args.ptb_rate,\n",
    "        \"ptb_sample_num\": args.num_samples,\n",
    "        \"ptb_sample_size\": args.sample_size,\n",
    "        \"base_g0\": baseline_acc[\"g0\"],\n",
    "        \"base_gX\": baseline_acc[\"gX\"],\n",
    "        \"d_g0\": dg0,\n",
    "        \"d_gX\": dgX,\n",
    "    }\n",
    "    t = 0\n",
    "    for idx in torch.randint(0, graph.features.shape[1], [5]):\n",
    "        taskLabels, taskFeatures = Utils.get_task(idx, graph.features, device)\n",
    "\n",
    "        tempModelBase = GCN(\n",
    "            input_features=taskFeatures.shape[1],\n",
    "            output_classes=taskLabels.max().item()+1,\n",
    "            hidden_layers=args.hidden_layers,\n",
    "            device=device,\n",
    "            lr=args.model_lr,\n",
    "            dropout=args.dropout,\n",
    "            weight_decay=args.weight_decay,\n",
    "            name=f\"task {idx:.0f}\"\n",
    "        )\n",
    "\n",
    "        tempModelBase.fitManual(taskFeatures, graph.adj, taskLabels, graph.idx_train, graph.idx_test, args.reg_epochs)\n",
    "\n",
    "        pred = tempModelBase(taskFeatures, graph.adj)\n",
    "        tempAccBase = Metrics.partial_acc(pred, taskLabels, g0, gX, verbose=False)\n",
    "\n",
    "        tempModel = GCN(\n",
    "            input_features=taskFeatures.shape[1],\n",
    "            output_classes=taskLabels.max().item()+1,\n",
    "            hidden_layers=args.hidden_layers,\n",
    "            device=device,\n",
    "            lr=args.model_lr,\n",
    "            dropout=args.dropout,\n",
    "            weight_decay=args.weight_decay,\n",
    "            name=f\"task {idx:.0f} locked\"\n",
    "        )\n",
    "\n",
    "        tempModel.fitManual(taskFeatures, locked_adj, taskLabels, graph.idx_train, graph.idx_test, args.reg_epochs)\n",
    "\n",
    "        pred = tempModel(taskFeatures, locked_adj)\n",
    "        tempAcc = Metrics.partial_acc(pred, taskLabels, g0, gX, verbose=False)\n",
    "\n",
    "        d_g0 = tempAcc[\"g0\"] - tempAccBase[\"g0\"]\n",
    "        d_gX = tempAcc[\"gX\"] - tempAccBase[\"gX\"]\n",
    "\n",
    "        print(f\"d_g0: {d_g0:.2%}\")\n",
    "        print(f\"d_gX: {d_gX:.2%}\")\n",
    "\n",
    "        universalResults[f\"t{t:.0f}_task\"] = idx\n",
    "        universalResults[f\"t{t:.0f}_g0\"] = tempAccBase[\"g0\"]\n",
    "        universalResults[f\"d_t{t:.0f}_g0\"] = d_g0\n",
    "        universalResults[f\"t{t:.0f}_gX\"] = tempAccBase[\"gX\"]\n",
    "        universalResults[f\"d_t{t:.0f}_gX\"] = d_gX\n",
    "\n",
    "        t += 1\n",
    "    \n",
    "    sp = args.save_location.split(\".\")\n",
    "    sp = sp[:-1] + [\"Universal\"] + sp[-1:]\n",
    "    sp = \".\".join(sp)\n",
    "    Export.saveData(sp, universalResults)\n",
    "\n",
    "\n",
    "################################################\n",
    "# Save\n",
    "################################################\n",
    "\n",
    "if (args.save == \"Y\"):\n",
    "    import Utils.Export as Export\n",
    "    from datetime import datetime\n",
    "\n",
    "    def getDiff(location, changeType):\n",
    "        num = diffSummary[location][changeType][\"total\"]\n",
    "        if num == 0: return f\"{num:.0f}\"\n",
    "        pct = diffSummary[location][changeType][\"same\"] / num\n",
    "        return f\"{num:.0f} ({pct:.2%} similar)\"\n",
    "\n",
    "    results = {\n",
    "        \"seed\": args.seed,\n",
    "        \"dataset\": args.dataset,\n",
    "        \"protect_size\": args.protect_size,\n",
    "        \"reg_epochs\": args.reg_epochs,\n",
    "        \"ptb_epochs\": args.ptb_epochs,\n",
    "        \"ptb_rate\": args.ptb_rate,\n",
    "        \"ptb_sample_num\": args.num_samples,\n",
    "        \"ptb_sample_size\": args.sample_size,\n",
    "        \"ratio_g0\": samplingMatrix.g0_ratio.item(),\n",
    "        \"ratio_gX\": samplingMatrix.gX_ratio.item(),\n",
    "        \"ratio_g0gX\": samplingMatrix.g0gX_ratio.item(),\n",
    "        \"base_g0\": baseline_acc[\"g0\"],\n",
    "        \"base_gX\": baseline_acc[\"gX\"],\n",
    "        \"d_g0\": dg0,\n",
    "        \"d_gX\": dgX,\n",
    "        \"edges\": diff.abs().sum().item(),\n",
    "        \"add_g0\": getDiff(\"g0\", \"add\"),\n",
    "        \"add_gX\": getDiff(\"gX\", \"add\"),\n",
    "        \"add_g0gX\": getDiff(\"g0gX\", \"add\"),\n",
    "        \"remove_g0\": getDiff(\"g0\", \"remove\"),\n",
    "        \"remove_gX\": getDiff(\"gX\", \"remove\"),\n",
    "        \"remove_g0gX\": getDiff(\"g0gX\", \"remove\"),\n",
    "\n",
    "    }\n",
    "\n",
    "    Export.saveData(args.save_location, results)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "284a17d5edba1b82bbb8793a64a3a9f6114640b8c8687fac297a1d74e5a299a9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pygraph')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
