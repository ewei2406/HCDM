{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.path.abspath(''), '../..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Environment:  torch 1.10.2 \tdevice: cpu \tseed: 123\n",
      "[i] Dataset: cora\n",
      "Loading cora dataset...\n",
      "\n",
      "[i] Dataset Summary: \n",
      "\tadj shape: [2708, 2708]\n",
      "\tfeature shape: [2708, 1433]\n",
      "\tnum labels: 7\n",
      "\tsplit seed: 123\n",
      "\ttrain|val|test: 140|500|1000\n",
      "[i] Number of protected nodes: 285 (10.52%)\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "#region Arguments\n",
    "\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--save', type=str, default='./out.csv', help='save the outputs to csv')\n",
    "\n",
    "# data args\n",
    "parser.add_argument('--seed', type=int, default=123, help='Random seed for model')\n",
    "parser.add_argument('--dataset', type=str, default='cora', help='dataset')\n",
    "parser.add_argument('--protect_size', type=float, default=0.1, help='Number of randomly chosen protected nodes')\n",
    "\n",
    "# attack args\n",
    "parser.add_argument('--ptb_rate', type=float, default=0.25, help='Perturbation rate (percentage of available edges)')\n",
    "parser.add_argument('--ptb_epochs', type=int, default=3, help='Epochs to perturb adj matrix')\n",
    "parser.add_argument('--sample_size', type=int, default=50, help='')\n",
    "parser.add_argument('--num_samples', type=int, default=2, help='')\n",
    "parser.add_argument('--num_subtasks', type=int, default=30, help='')\n",
    "\n",
    "# model args\n",
    "parser.add_argument('--reg_epochs', type=int, default=10, help='Epochs to train models')\n",
    "parser.add_argument('--model_lr', type=float, default=0.01, help='Initial learning rate')\n",
    "parser.add_argument('--weight_decay', type=float, default=5e-4, help='Weight decay (L2 loss on parameters)')\n",
    "parser.add_argument('--hidden_layers', type=int, default=32, help='Number of hidden layers')\n",
    "parser.add_argument('--dropout', type=float, default=0.5, help='Dropout rate for GCN')\n",
    "\n",
    "\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "#endregion\n",
    "##########################\n",
    "\n",
    "##########################\n",
    "#region Environment\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "if device != 'cpu':\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "print(f'[i] Environment:  torch {torch.__version__} \\tdevice: {device} \\tseed: {args.seed}')\n",
    "\n",
    "#endregion\n",
    "##########################\n",
    "\n",
    "########################\n",
    "#region Data\n",
    "\n",
    "from Utils import GraphData\n",
    "\n",
    "print(f'[i] Dataset: {args.dataset}')\n",
    "\n",
    "graph = GraphData.getGraph(\"../../Datasets\", args.dataset, \"gcn\", args.seed, device)\n",
    "graph.summarize()\n",
    "\n",
    "#endregion\n",
    "########################\n",
    "\n",
    "########################\n",
    "#region Designate Protected\n",
    "\n",
    "g0 = torch.rand(graph.features.shape[0]) <= args.protect_size\n",
    "g0 = g0.to(device)\n",
    "gX = ~g0\n",
    "print(f\"[i] Number of protected nodes: {g0.sum():.0f} ({g0.sum() / graph.features.shape[0]:.2%})\")\n",
    "\n",
    "#endregion\n",
    "########################\n",
    "\n",
    "########################\n",
    "#region Sampling Matrix\n",
    "\n",
    "from Utils import SamplingMatrix\n",
    "\n",
    "samplingMatrix = SamplingMatrix.SamplingMatrix(g0, gX, graph.adj, args.sample_size)\n",
    "\n",
    "#endregion\n",
    "########################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for [cora_selected]\n",
      "Failed to find data for [cora_selected]\n",
      "Saving data for [cora_selected]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "########################\n",
    "#region Feature Selection\n",
    "\n",
    "from Utils import FeatureMetrics\n",
    "from Utils import Utils\n",
    "from Utils import Export\n",
    "\n",
    "metrics = Export.load_var(\"cora_selected\")\n",
    "\n",
    "if metrics == None:\n",
    "    transposed = graph.features.t().contiguous()\n",
    "    metrics = torch.zeros([3, transposed.shape[0]])\n",
    "\n",
    "    for i in range(transposed.shape[0]):\n",
    "        metrics[0][i] = i\n",
    "        metrics[1][i] = FeatureMetrics.shannon_entropy(transposed[i])\n",
    "        metrics[2][i] = FeatureMetrics.chi_squared(transposed[i], graph.labels)\n",
    "\n",
    "    select_idx = FeatureMetrics.sample_by_quantiles(metrics[0], metrics[1], n_bins=4, n_samples=args.num_subtasks)\n",
    "    metrics = metrics[:, select_idx == 1]\n",
    "    Export.save_var(\"cora_selected\", metrics.numpy().tolist())\n",
    "else:\n",
    "    metrics = torch.tensor(metrics)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(metrics[1], metrics[2])\n",
    "\n",
    "selected = Utils.idx_to_bool(metrics[0].long())\n",
    "\n",
    "tasks = {\n",
    "    -1: graph.labels\n",
    "}\n",
    "for i in Utils.bool_to_idx(selected):\n",
    "    tasks[i.item()] = graph.features[:, i].squeeze()\n",
    "\n",
    "#endregion\n",
    "########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.features = graph.features[:,Utils.bool_to_idx(~selected)].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing: 100%|██████████| 3/3 [00:01<00:00,  2.10it/s, adj_l=0.00297, adj_g=0, pre-p=7, target=1319, loss=tensor(0.0030, grad_fn=<SubBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "########################\n",
    "#region Do perturbation\n",
    "\n",
    "from Models.GCN import GCN\n",
    "\n",
    "surrogate = GCN(\n",
    "    input_features=graph.features.shape[1],\n",
    "    output_classes=graph.labels.max().item()+1,\n",
    "    hidden_layers=args.hidden_layers,\n",
    "    device=device,\n",
    "    lr=args.model_lr,\n",
    "    dropout=args.dropout,\n",
    "    weight_decay=args.weight_decay,\n",
    "    name=f\"surrogate\"\n",
    ").to(device)\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "perturbations = torch.zeros_like(graph.adj).float()\n",
    "count = torch.zeros_like(graph.adj).float()\n",
    "num_perturbations = args.ptb_rate * graph.adj.sum()\n",
    "\n",
    "t = tqdm(range(args.ptb_epochs), bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}')\n",
    "t.set_description(\"Perturbing\")\n",
    "\n",
    "for epoch in t:\n",
    "\n",
    "    # Re-initialize adj_grad\n",
    "    adj_grad = torch.zeros_like(graph.adj).float()\n",
    "\n",
    "    # Get modified adj\n",
    "    modified_adj = Utils.get_modified_adj(graph.adj, perturbations).float().to(device)\n",
    "\n",
    "    # Do sampling\n",
    "    for sample_epoch in range(args.num_samples):\n",
    "        # Get sample indices\n",
    "        # sampled = torch.bernoulli(sampling_matrix)\n",
    "        idx = samplingMatrix.get_sample()\n",
    "        # print(idx)\n",
    "\n",
    "        # Map sample to adj\n",
    "        sample = modified_adj[idx[0], idx[1]].clone().detach().requires_grad_(True).to(device)\n",
    "        modified_adj[idx[0], idx[1]] = sample\n",
    "\n",
    "        # Get grad\n",
    "        predictions = surrogate(graph.features, modified_adj)\n",
    "        loss = F.cross_entropy(predictions[g0], graph.labels[g0]) \\\n",
    "            - F.cross_entropy(predictions[gX], graph.labels[gX])\n",
    "\n",
    "        grad = torch.autograd.grad(loss, sample)[0]\n",
    "\n",
    "        # Implement averaging\n",
    "        adj_grad[idx[0], idx[1]] += grad\n",
    "        count[idx[0], idx[1]] += 1\n",
    "\n",
    "        # Update the sampling matrix\n",
    "        samplingMatrix.updateByGrad(adj_grad, count)\n",
    "        samplingMatrix.getRatio()\n",
    "\n",
    "        # Average the gradient\n",
    "        adj_grad = torch.div(adj_grad, count)\n",
    "        adj_grad[adj_grad != adj_grad] = 0 # clear NaN\n",
    "    \n",
    "    # Update perturbations\n",
    "    lr = (num_perturbations) / (epoch + 1)\n",
    "    pre_projection = int(perturbations.sum() / 2)\n",
    "    perturbations = perturbations + (lr * adj_grad)\n",
    "    perturbations = Utils.projection(perturbations, num_perturbations)\n",
    "\n",
    "    # Train the model\n",
    "    modified_adj = Utils.get_modified_adj(graph.adj, perturbations)\n",
    "    surrogate.train1epoch(graph.features, modified_adj, graph.labels, graph.idx_train, graph.idx_test)\n",
    "\n",
    "    t.set_postfix({\"adj_l\": loss.item(),\n",
    "                    \"adj_g\": int(adj_grad.sum()),\n",
    "                    \"pre-p\": pre_projection,\n",
    "                    \"target\": int(num_perturbations / 2),\n",
    "                    \"loss\": loss})\n",
    "\n",
    "\n",
    "#endregion\n",
    "########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best sample loss: 0.04\t Edges: 14\n"
     ]
    }
   ],
   "source": [
    "########################\n",
    "#region Get sample\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    max_loss = -1000\n",
    "\n",
    "    for k in range(0,3):\n",
    "        sample = torch.bernoulli(perturbations)\n",
    "        modified_adj = Utils.get_modified_adj(graph.adj, perturbations)\n",
    "        modified_adj = Utils.make_symmetric(modified_adj) # Removing this creates \"impossible\" adj, but works well\n",
    "\n",
    "        predictions = surrogate(graph.features, modified_adj) \n",
    "\n",
    "        loss = F.cross_entropy(predictions[g0], graph.labels[g0]) \\\n",
    "            - F.cross_entropy(predictions[gX], graph.labels[gX])\n",
    "\n",
    "        if loss > max_loss:\n",
    "            max_loss = loss\n",
    "            best = sample\n",
    "    \n",
    "    print(f\"Best sample loss: {loss:.2f}\\t Edges: {best.abs().sum() / 2:.0f}\")\n",
    "\n",
    "#endregion\n",
    "########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b_g0\tl_g0\tb_gX\tl_gX\n",
      "68.1%\t66.0%\t70.1%\t69.7%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ewei/HCDM_Code/Experiment/FeatureSelection/FeatureSelection.ipynb Cell 6'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ewei/HCDM_Code/Experiment/FeatureSelection/FeatureSelection.ipynb#ch0000005?line=31'>32</a>\u001b[0m labels \u001b[39m=\u001b[39m FeatureMetrics\u001b[39m.\u001b[39mdiscretize(tasks[task_idx])\u001b[39m.\u001b[39mlong()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ewei/HCDM_Code/Experiment/FeatureSelection/FeatureSelection.ipynb#ch0000005?line=32'>33</a>\u001b[0m base_g0, base_gX \u001b[39m=\u001b[39m runtrial(graph\u001b[39m.\u001b[39madj, labels)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ewei/HCDM_Code/Experiment/FeatureSelection/FeatureSelection.ipynb#ch0000005?line=33'>34</a>\u001b[0m lock_g0, lock_gX \u001b[39m=\u001b[39m runtrial(locked_adj, labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ewei/HCDM_Code/Experiment/FeatureSelection/FeatureSelection.ipynb#ch0000005?line=34'>35</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mbase_g0\u001b[39m:\u001b[39;00m\u001b[39m.1%\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{\u001b[39;00mlock_g0\u001b[39m:\u001b[39;00m\u001b[39m.1%\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{\u001b[39;00mbase_gX\u001b[39m:\u001b[39;00m\u001b[39m.1%\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{\u001b[39;00mlock_gX\u001b[39m:\u001b[39;00m\u001b[39m.1%\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ewei/HCDM_Code/Experiment/FeatureSelection/FeatureSelection.ipynb#ch0000005?line=36'>37</a>\u001b[0m row \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ewei/HCDM_Code/Experiment/FeatureSelection/FeatureSelection.ipynb#ch0000005?line=37'>38</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mseed\u001b[39m\u001b[39m\"\u001b[39m: args\u001b[39m.\u001b[39mseed,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ewei/HCDM_Code/Experiment/FeatureSelection/FeatureSelection.ipynb#ch0000005?line=38'>39</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdataset\u001b[39m\u001b[39m\"\u001b[39m: args\u001b[39m.\u001b[39mdataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ewei/HCDM_Code/Experiment/FeatureSelection/FeatureSelection.ipynb#ch0000005?line=52'>53</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39medges\u001b[39m\u001b[39m\"\u001b[39m: edges\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ewei/HCDM_Code/Experiment/FeatureSelection/FeatureSelection.ipynb#ch0000005?line=53'>54</a>\u001b[0m }\n",
      "\u001b[1;32m/Users/ewei/HCDM_Code/Experiment/FeatureSelection/FeatureSelection.ipynb Cell 6'\u001b[0m in \u001b[0;36mruntrial\u001b[0;34m(adj, labels)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ewei/HCDM_Code/Experiment/FeatureSelection/FeatureSelection.ipynb#ch0000005?line=4'>5</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ewei/HCDM_Code/Experiment/FeatureSelection/FeatureSelection.ipynb#ch0000005?line=5'>6</a>\u001b[0m \u001b[39mReturn the accuracy over g0 and gX of a GCN trained using adj with respect to labels\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ewei/HCDM_Code/Experiment/FeatureSelection/FeatureSelection.ipynb#ch0000005?line=6'>7</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ewei/HCDM_Code/Experiment/FeatureSelection/FeatureSelection.ipynb#ch0000005?line=7'>8</a>\u001b[0m model \u001b[39m=\u001b[39m GCN(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ewei/HCDM_Code/Experiment/FeatureSelection/FeatureSelection.ipynb#ch0000005?line=8'>9</a>\u001b[0m     input_features\u001b[39m=\u001b[39mgraph\u001b[39m.\u001b[39mfeatures\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ewei/HCDM_Code/Experiment/FeatureSelection/FeatureSelection.ipynb#ch0000005?line=9'>10</a>\u001b[0m     output_classes\u001b[39m=\u001b[39mlabels\u001b[39m.\u001b[39mmax()\u001b[39m.\u001b[39mitem() \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ewei/HCDM_Code/Experiment/FeatureSelection/FeatureSelection.ipynb#ch0000005?line=15'>16</a>\u001b[0m     name\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbaseline\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ewei/HCDM_Code/Experiment/FeatureSelection/FeatureSelection.ipynb#ch0000005?line=16'>17</a>\u001b[0m )\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ewei/HCDM_Code/Experiment/FeatureSelection/FeatureSelection.ipynb#ch0000005?line=18'>19</a>\u001b[0m model\u001b[39m.\u001b[39;49mfitManual(graph\u001b[39m.\u001b[39;49mfeatures, adj, labels, graph\u001b[39m.\u001b[39;49midx_train, graph\u001b[39m.\u001b[39;49midx_test, args\u001b[39m.\u001b[39;49mreg_epochs, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ewei/HCDM_Code/Experiment/FeatureSelection/FeatureSelection.ipynb#ch0000005?line=19'>20</a>\u001b[0m pred \u001b[39m=\u001b[39m model(graph\u001b[39m.\u001b[39mfeatures, adj)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ewei/HCDM_Code/Experiment/FeatureSelection/FeatureSelection.ipynb#ch0000005?line=20'>21</a>\u001b[0m acc_g0 \u001b[39m=\u001b[39m FeatureMetrics\u001b[39m.\u001b[39mcategorical_accuracy(labels[g0], pred[g0]\u001b[39m.\u001b[39margmax(\u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m~/HCDM_Code/Experiment/FeatureSelection/../../Models/GCN.py:51\u001b[0m, in \u001b[0;36mGCN.fitManual\u001b[0;34m(self, features, adj, labels, idx_train, idx_test, epochs, verbose)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/ewei/HCDM_Code/Experiment/FeatureSelection/../../Models/GCN.py?line=48'>49</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m t:\n\u001b[1;32m     <a href='file:///Users/ewei/HCDM_Code/Experiment/FeatureSelection/../../Models/GCN.py?line=49'>50</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='file:///Users/ewei/HCDM_Code/Experiment/FeatureSelection/../../Models/GCN.py?line=50'>51</a>\u001b[0m     predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(features, adj)\n\u001b[1;32m     <a href='file:///Users/ewei/HCDM_Code/Experiment/FeatureSelection/../../Models/GCN.py?line=52'>53</a>\u001b[0m     loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mcross_entropy(predictions[idx_train], labels[idx_train])\n\u001b[1;32m     <a href='file:///Users/ewei/HCDM_Code/Experiment/FeatureSelection/../../Models/GCN.py?line=54'>55</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/pygraph/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/anaconda3/envs/pygraph/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/anaconda3/envs/pygraph/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/anaconda3/envs/pygraph/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///opt/homebrew/anaconda3/envs/pygraph/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///opt/homebrew/anaconda3/envs/pygraph/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///opt/homebrew/anaconda3/envs/pygraph/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/anaconda3/envs/pygraph/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/HCDM_Code/Experiment/FeatureSelection/../../Models/GCN.py:29\u001b[0m, in \u001b[0;36mGCN.forward\u001b[0;34m(self, x, adj)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/ewei/HCDM_Code/Experiment/FeatureSelection/../../Models/GCN.py?line=26'>27</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(x)\n\u001b[1;32m     <a href='file:///Users/ewei/HCDM_Code/Experiment/FeatureSelection/../../Models/GCN.py?line=27'>28</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mdropout(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n\u001b[0;32m---> <a href='file:///Users/ewei/HCDM_Code/Experiment/FeatureSelection/../../Models/GCN.py?line=28'>29</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2(x, adj)\n\u001b[1;32m     <a href='file:///Users/ewei/HCDM_Code/Experiment/FeatureSelection/../../Models/GCN.py?line=30'>31</a>\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mlog_softmax(x, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39msqueeze()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/pygraph/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/anaconda3/envs/pygraph/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/anaconda3/envs/pygraph/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/anaconda3/envs/pygraph/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///opt/homebrew/anaconda3/envs/pygraph/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///opt/homebrew/anaconda3/envs/pygraph/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///opt/homebrew/anaconda3/envs/pygraph/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/anaconda3/envs/pygraph/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/pygraph/lib/python3.9/site-packages/torch_geometric/nn/dense/dense_gcn_conv.py:62\u001b[0m, in \u001b[0;36mDenseGCNConv.forward\u001b[0;34m(self, x, adj, mask, add_loop)\u001b[0m\n\u001b[1;32m     <a href='file:///opt/homebrew/anaconda3/envs/pygraph/lib/python3.9/site-packages/torch_geometric/nn/dense/dense_gcn_conv.py?line=58'>59</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlin(x)\n\u001b[1;32m     <a href='file:///opt/homebrew/anaconda3/envs/pygraph/lib/python3.9/site-packages/torch_geometric/nn/dense/dense_gcn_conv.py?line=59'>60</a>\u001b[0m deg_inv_sqrt \u001b[39m=\u001b[39m adj\u001b[39m.\u001b[39msum(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mclamp(\u001b[39mmin\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mpow(\u001b[39m-\u001b[39m\u001b[39m0.5\u001b[39m)\n\u001b[0;32m---> <a href='file:///opt/homebrew/anaconda3/envs/pygraph/lib/python3.9/site-packages/torch_geometric/nn/dense/dense_gcn_conv.py?line=61'>62</a>\u001b[0m adj \u001b[39m=\u001b[39m deg_inv_sqrt\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m) \u001b[39m*\u001b[39;49m adj \u001b[39m*\u001b[39m deg_inv_sqrt\u001b[39m.\u001b[39munsqueeze(\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m     <a href='file:///opt/homebrew/anaconda3/envs/pygraph/lib/python3.9/site-packages/torch_geometric/nn/dense/dense_gcn_conv.py?line=62'>63</a>\u001b[0m out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmatmul(adj, out)\n\u001b[1;32m     <a href='file:///opt/homebrew/anaconda3/envs/pygraph/lib/python3.9/site-packages/torch_geometric/nn/dense/dense_gcn_conv.py?line=64'>65</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "########################\n",
    "#region Evaluation\n",
    "\n",
    "def runtrial(adj, labels):\n",
    "    \"\"\"\n",
    "    Return the accuracy over g0 and gX of a GCN trained using adj with respect to labels\n",
    "    \"\"\"\n",
    "    model = GCN(\n",
    "        input_features=graph.features.shape[1],\n",
    "        output_classes=labels.max().item() + 1,\n",
    "        hidden_layers=args.hidden_layers,\n",
    "        device=device,\n",
    "        lr=args.model_lr,\n",
    "        dropout=args.dropout,\n",
    "        weight_decay=args.weight_decay,\n",
    "        name=f\"baseline\"\n",
    "    ).to(device)\n",
    "\n",
    "    model.fitManual(graph.features, adj, labels, graph.idx_train, graph.idx_test, args.reg_epochs, False)\n",
    "    pred = model(graph.features, adj)\n",
    "    acc_g0 = FeatureMetrics.categorical_accuracy(labels[g0], pred[g0].argmax(1))\n",
    "    acc_gX = FeatureMetrics.categorical_accuracy(labels[gX], pred[gX].argmax(1))\n",
    "\n",
    "    return acc_g0, acc_gX\n",
    "\n",
    "locked_adj = Utils.get_modified_adj(graph.adj, best)\n",
    "diff = locked_adj - graph.adj\n",
    "edges = int(diff.abs().sum().item())\n",
    "\n",
    "print(f\"b_g0\\tl_g0\\tb_gX\\tl_gX\")\n",
    "for task_idx in tasks:\n",
    "    labels = FeatureMetrics.discretize(tasks[task_idx]).long()\n",
    "    base_g0, base_gX = runtrial(graph.adj, labels)\n",
    "    lock_g0, lock_gX = runtrial(locked_adj, labels)\n",
    "    print(f\"{base_g0:.1%}\\t{lock_g0:.1%}\\t{base_gX:.1%}\\t{lock_gX:.1%}\")\n",
    "\n",
    "    row = {\n",
    "        \"seed\": args.seed,\n",
    "        \"dataset\": args.dataset,\n",
    "        \"protect_size\": args.protect_size,\n",
    "        \"reg_epochs\": args.reg_epochs,\n",
    "        \"ptb_epochs\": args.ptb_epochs,\n",
    "        \"ptb_rate\": args.ptb_rate,\n",
    "        \"ptb_sample_num\": args.num_samples,\n",
    "        \"ptb_sample_size\": args.sample_size,\n",
    "        \"task_idx\": task_idx,\n",
    "        \"base_g0\": base_g0,\n",
    "        \"base_gX\": base_gX,\n",
    "        \"lock_g0\": lock_g0,\n",
    "        \"lock_gX\": lock_gX,\n",
    "        \"rel_g0\": 1 - (lock_g0 / base_g0),\n",
    "        \"rel_gX\": 1 - (lock_gX / base_gX),\n",
    "        \"edges\": edges\n",
    "    }\n",
    "    \n",
    "    if args.save != 'N':\n",
    "        Export.saveData(args.save, row)\n",
    "\n",
    "#endregion\n",
    "########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "#region Evaluation\n",
    "\n",
    "from Utils import Export\n",
    "\n",
    "print(\"==== Evaluation ====\")\n",
    "print(f\"Task,\\tG0,\\tGX,\\tD_G0\\tD_GX\")\n",
    "\n",
    "locked_adj = Utils.get_modified_adj(graph.adj, best)\n",
    "diff = locked_adj - graph.adj\n",
    "\n",
    "for task_idx in range(selected_feat.shape[0]):\n",
    "    temp_labels = tasks[t][\"feat\"].long()\n",
    "    label_max = temp_labels.max().item() + 1\n",
    "\n",
    "    baseline_model = GCN(\n",
    "        input_features=graph.features.shape[1],\n",
    "        output_classes=label_max,\n",
    "        hidden_layers=args.hidden_layers,\n",
    "        device=device,\n",
    "        lr=args.model_lr,\n",
    "        dropout=args.dropout,\n",
    "        weight_decay=args.weight_decay,\n",
    "        name=f\"baseline\"\n",
    "    ).to(device)\n",
    "\n",
    "    baseline_model.fitManual(graph.features, graph.adj, temp_labels, graph.idx_train, graph.idx_test, args.reg_epochs, False)\n",
    "\n",
    "    pred = baseline_model(graph.features, graph.adj)\n",
    "    baseline_acc = Metrics.partial_acc(pred, temp_labels, g0, gX, False)\n",
    "\n",
    "\n",
    "    locked_model = GCN(\n",
    "        input_features=graph.features.shape[1],\n",
    "        output_classes=label_max,\n",
    "        hidden_layers=args.hidden_layers,\n",
    "        device=device,\n",
    "        lr=args.model_lr,\n",
    "        dropout=args.dropout,\n",
    "        weight_decay=args.weight_decay,\n",
    "        name=f\"locked\"\n",
    "    )\n",
    "\n",
    "    locked_model.fitManual(graph.features, locked_adj, temp_labels, graph.idx_train, graph.idx_test, args.reg_epochs, False)\n",
    "\n",
    "    pred = locked_model(graph.features, locked_adj)\n",
    "    locked_acc = Metrics.partial_acc(pred, temp_labels, g0, gX, False)\n",
    "\n",
    "    dg0 = locked_acc[\"g0\"] - baseline_acc[\"g0\"]\n",
    "    dgX = locked_acc[\"gX\"] - baseline_acc[\"gX\"]\n",
    "\n",
    "    print(f\"{t},\\t{dg0:.1%},\\t{dgX:.1%},\\t{tasks[t]['ent']:.2f},\\t{tasks[t]['corr']:.2f}\")\n",
    "\n",
    "    diffSummary = Metrics.show_metrics(diff, temp_labels, g0, device, False)\n",
    "\n",
    "    results = {\n",
    "        \"seed\": args.seed,\n",
    "        \"dataset\": args.dataset,\n",
    "        \"protect_size\": args.protect_size,\n",
    "        \"reg_epochs\": args.reg_epochs,\n",
    "        \"ptb_epochs\": args.ptb_epochs,\n",
    "        \"ptb_rate\": args.ptb_rate,\n",
    "        \"ptb_sample_num\": args.num_samples,\n",
    "        \"ptb_sample_size\": args.sample_size,\n",
    "        \"ratio_g0\": samplingMatrix.g0_ratio.item(),\n",
    "        \"ratio_gX\": samplingMatrix.gX_ratio.item(),\n",
    "        \"ratio_g0gX\": samplingMatrix.g0gX_ratio.item(),\n",
    "        \"feature\": t,\n",
    "        \"corr\": tasks[t][\"corr\"],\n",
    "        \"entropy\": tasks[t][\"ent\"],\n",
    "        \"base_g0\": baseline_acc[\"g0\"],\n",
    "        \"base_gX\": baseline_acc[\"gX\"],\n",
    "        \"d_g0\": dg0,\n",
    "        \"d_gX\": dgX,\n",
    "        \"edges\": int(diff.abs().sum().item()),\n",
    "    }\n",
    "\n",
    "    for add_remove in [\"add\", \"remove\"]:\n",
    "        for location in [\"g0\", \"gX\", \"g0gX\"]:\n",
    "            for similar in [\"same\", \"diff\"]:\n",
    "                results[\"_\".join([add_remove, location, similar])] = diffSummary[location][add_remove][similar]\n",
    "\n",
    "    Export.saveData(args.save_location, results)\n",
    "\n",
    "#endregion\n",
    "########################\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "284a17d5edba1b82bbb8793a64a3a9f6114640b8c8687fac297a1d74e5a299a9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pygraph')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
