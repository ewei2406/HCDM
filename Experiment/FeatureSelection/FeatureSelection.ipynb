{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.path.abspath(''), '../..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Environment:  torch 1.10.2 \tdevice: cpu \tseed: 123\n",
      "[i] Dataset: cora\n",
      "Loading cora dataset...\n",
      "\n",
      "[i] Dataset Summary: \n",
      "\tadj shape: [2708, 2708]\n",
      "\tfeature shape: [2708, 1433]\n",
      "\tnum labels: 7\n",
      "\tsplit seed: 123\n",
      "\ttrain|val|test: 140|500|1000\n",
      "[i] Number of protected nodes: 285 (10.52%)\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "#region Arguments\n",
    "\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--save', type=str, default='./out.csv', help='save the outputs to csv')\n",
    "\n",
    "# data args\n",
    "parser.add_argument('--seed', type=int, default=123, help='Random seed for model')\n",
    "parser.add_argument('--dataset', type=str, default='cora', help='dataset')\n",
    "parser.add_argument('--protect_size', type=float, default=0.1, help='Number of randomly chosen protected nodes')\n",
    "\n",
    "# attack args\n",
    "parser.add_argument('--ptb_rate', type=float, default=0.25, help='Perturbation rate (percentage of available edges)')\n",
    "parser.add_argument('--ptb_epochs', type=int, default=3, help='Epochs to perturb adj matrix')\n",
    "parser.add_argument('--sample_size', type=int, default=50, help='')\n",
    "parser.add_argument('--num_samples', type=int, default=2, help='')\n",
    "parser.add_argument('--num_subtasks', type=int, default=2, help='')\n",
    "\n",
    "# model args\n",
    "parser.add_argument('--reg_epochs', type=int, default=10, help='Epochs to train models')\n",
    "parser.add_argument('--model_lr', type=float, default=0.01, help='Initial learning rate')\n",
    "parser.add_argument('--weight_decay', type=float, default=5e-4, help='Weight decay (L2 loss on parameters)')\n",
    "parser.add_argument('--hidden_layers', type=int, default=32, help='Number of hidden layers')\n",
    "parser.add_argument('--dropout', type=float, default=0.5, help='Dropout rate for GCN')\n",
    "\n",
    "\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "#endregion\n",
    "##########################\n",
    "\n",
    "##########################\n",
    "#region Environment\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "if device != 'cpu':\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "print(f'[i] Environment:  torch {torch.__version__} \\tdevice: {device} \\tseed: {args.seed}')\n",
    "\n",
    "#endregion\n",
    "##########################\n",
    "\n",
    "########################\n",
    "#region Data\n",
    "\n",
    "from Utils import GraphData\n",
    "\n",
    "print(f'[i] Dataset: {args.dataset}')\n",
    "\n",
    "graph = GraphData.getGraph(\"../../Datasets\", args.dataset, \"gcn\", args.seed, device)\n",
    "graph.summarize()\n",
    "\n",
    "#endregion\n",
    "########################\n",
    "\n",
    "########################\n",
    "#region Designate Protected\n",
    "\n",
    "g0 = torch.rand(graph.features.shape[0]) <= args.protect_size\n",
    "g0 = g0.to(device)\n",
    "gX = ~g0\n",
    "print(f\"[i] Number of protected nodes: {g0.sum():.0f} ({g0.sum() / graph.features.shape[0]:.2%})\")\n",
    "\n",
    "#endregion\n",
    "########################\n",
    "\n",
    "########################\n",
    "#region Sampling Matrix\n",
    "\n",
    "from Utils import SamplingMatrix\n",
    "\n",
    "samplingMatrix = SamplingMatrix.SamplingMatrix(g0, gX, graph.adj, args.sample_size)\n",
    "\n",
    "#endregion\n",
    "########################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for [cora_selected]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "########################\n",
    "#region Feature Selection\n",
    "\n",
    "from Utils import FeatureMetrics\n",
    "from Utils import Utils\n",
    "from Utils import Export\n",
    "\n",
    "metrics = Export.load_var(\"cora_selected\")\n",
    "\n",
    "if metrics == None:\n",
    "    transposed = graph.features.t().contiguous()\n",
    "    metrics = torch.zeros([3, transposed.shape[0]])\n",
    "\n",
    "    for i in range(transposed.shape[0]):\n",
    "        metrics[0][i] = i\n",
    "        metrics[1][i] = FeatureMetrics.shannon_entropy(transposed[i])\n",
    "        metrics[2][i] = FeatureMetrics.chi_squared(transposed[i], graph.labels)\n",
    "\n",
    "    select_idx = FeatureMetrics.sample_by_quantiles(metrics[0], metrics[1], n_bins=4, n_samples=args.num_subtasks)\n",
    "    metrics = metrics[:, select_idx == 1]\n",
    "    Export.save_var(\"cora_selected\", metrics.numpy().tolist())\n",
    "else:\n",
    "    metrics = torch.tensor(metrics)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(metrics[1], metrics[2])\n",
    "\n",
    "selected = Utils.idx_to_bool(metrics[0].long())\n",
    "\n",
    "tasks = {\n",
    "    -1: graph.labels\n",
    "}\n",
    "for i in Utils.bool_to_idx(selected):\n",
    "    tasks[i.item()] = graph.features[:, i].squeeze()\n",
    "\n",
    "graph.features = graph.features[:,Utils.bool_to_idx(~selected)].squeeze()\n",
    "#endregion\n",
    "########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing: 100%|██████████| 3/3 [00:01<00:00,  2.08it/s, adj_l=0.00135, adj_g=0, pre-p=9, target=1319, loss=tensor(0.0013, grad_fn=<SubBackward0>)]  \n"
     ]
    }
   ],
   "source": [
    "########################\n",
    "#region Do perturbation\n",
    "\n",
    "from Models.GCN import GCN\n",
    "\n",
    "surrogate = GCN(\n",
    "    input_features=graph.features.shape[1],\n",
    "    output_classes=graph.labels.max().item()+1,\n",
    "    hidden_layers=args.hidden_layers,\n",
    "    device=device,\n",
    "    lr=args.model_lr,\n",
    "    dropout=args.dropout,\n",
    "    weight_decay=args.weight_decay,\n",
    "    name=f\"surrogate\"\n",
    ").to(device)\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "perturbations = torch.zeros_like(graph.adj).float()\n",
    "count = torch.zeros_like(graph.adj).float()\n",
    "num_perturbations = args.ptb_rate * graph.adj.sum()\n",
    "\n",
    "t = tqdm(range(args.ptb_epochs), bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}')\n",
    "t.set_description(\"Perturbing\")\n",
    "\n",
    "for epoch in t:\n",
    "\n",
    "    # Re-initialize adj_grad\n",
    "    adj_grad = torch.zeros_like(graph.adj).float()\n",
    "\n",
    "    # Get modified adj\n",
    "    modified_adj = Utils.get_modified_adj(graph.adj, perturbations).float().to(device)\n",
    "\n",
    "    # Do sampling\n",
    "    for sample_epoch in range(args.num_samples):\n",
    "        # Get sample indices\n",
    "        # sampled = torch.bernoulli(sampling_matrix)\n",
    "        idx = samplingMatrix.get_sample()\n",
    "        # print(idx)\n",
    "\n",
    "        # Map sample to adj\n",
    "        sample = modified_adj[idx[0], idx[1]].clone().detach().requires_grad_(True).to(device)\n",
    "        modified_adj[idx[0], idx[1]] = sample\n",
    "\n",
    "        # Get grad\n",
    "        predictions = surrogate(graph.features, modified_adj)\n",
    "        loss = F.cross_entropy(predictions[g0], graph.labels[g0]) \\\n",
    "            - F.cross_entropy(predictions[gX], graph.labels[gX])\n",
    "\n",
    "        grad = torch.autograd.grad(loss, sample)[0]\n",
    "\n",
    "        # Implement averaging\n",
    "        adj_grad[idx[0], idx[1]] += grad\n",
    "        count[idx[0], idx[1]] += 1\n",
    "\n",
    "        # Update the sampling matrix\n",
    "        samplingMatrix.updateByGrad(adj_grad, count)\n",
    "        samplingMatrix.getRatio()\n",
    "\n",
    "        # Average the gradient\n",
    "        adj_grad = torch.div(adj_grad, count)\n",
    "        adj_grad[adj_grad != adj_grad] = 0 # clear NaN\n",
    "    \n",
    "    # Update perturbations\n",
    "    lr = (num_perturbations) / (epoch + 1)\n",
    "    pre_projection = int(perturbations.sum() / 2)\n",
    "    perturbations = perturbations + (lr * adj_grad)\n",
    "    perturbations = Utils.projection(perturbations, num_perturbations)\n",
    "\n",
    "    # Train the model\n",
    "    modified_adj = Utils.get_modified_adj(graph.adj, perturbations)\n",
    "    surrogate.train1epoch(graph.features, modified_adj, graph.labels, graph.idx_train, graph.idx_test)\n",
    "\n",
    "    t.set_postfix({\"adj_l\": loss.item(),\n",
    "                    \"adj_g\": int(adj_grad.sum()),\n",
    "                    \"pre-p\": pre_projection,\n",
    "                    \"target\": int(num_perturbations / 2),\n",
    "                    \"loss\": loss})\n",
    "\n",
    "\n",
    "#endregion\n",
    "########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best sample loss: 0.01\t Edges: 14\n"
     ]
    }
   ],
   "source": [
    "########################\n",
    "#region Get sample\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    max_loss = -1000\n",
    "\n",
    "    for k in range(0,3):\n",
    "        sample = torch.bernoulli(perturbations)\n",
    "        modified_adj = Utils.get_modified_adj(graph.adj, perturbations)\n",
    "        modified_adj = Utils.make_symmetric(modified_adj) # Removing this creates \"impossible\" adj, but works well\n",
    "\n",
    "        predictions = surrogate(graph.features, modified_adj) \n",
    "\n",
    "        loss = F.cross_entropy(predictions[g0], graph.labels[g0]) \\\n",
    "            - F.cross_entropy(predictions[gX], graph.labels[gX])\n",
    "\n",
    "        if loss > max_loss:\n",
    "            max_loss = loss\n",
    "            best = sample\n",
    "    \n",
    "    print(f\"Best sample loss: {loss:.2f}\\t Edges: {best.abs().sum() / 2:.0f}\")\n",
    "\n",
    "#endregion\n",
    "########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b_g0\tl_g0\tb_gX\tl_gX\n",
      "70.5%\t68.4%\t75.7%\t71.3%\n",
      "21.8%\t24.2%\t24.1%\t23.9%\n",
      "25.6%\t26.7%\t24.7%\t27.1%\n",
      "19.3%\t21.1%\t22.0%\t23.4%\n",
      "21.8%\t26.7%\t22.9%\t25.3%\n",
      "20.7%\t22.1%\t23.2%\t22.0%\n",
      "26.7%\t23.5%\t26.5%\t24.8%\n",
      "22.1%\t22.5%\t23.2%\t23.6%\n",
      "22.5%\t24.6%\t22.9%\t25.5%\n",
      "23.5%\t25.3%\t23.4%\t25.8%\n",
      "20.7%\t23.9%\t22.2%\t26.1%\n",
      "19.6%\t22.8%\t22.5%\t22.4%\n",
      "20.7%\t21.8%\t21.3%\t23.3%\n",
      "24.6%\t22.1%\t23.4%\t24.4%\n",
      "23.2%\t23.9%\t21.5%\t25.9%\n",
      "22.1%\t20.4%\t23.0%\t23.0%\n",
      "20.0%\t21.4%\t22.6%\t20.3%\n",
      "22.5%\t20.4%\t24.3%\t20.9%\n",
      "22.5%\t23.2%\t22.5%\t24.3%\n",
      "22.1%\t25.6%\t23.9%\t25.9%\n",
      "25.6%\t22.8%\t25.2%\t23.8%\n",
      "21.8%\t22.5%\t22.7%\t21.4%\n",
      "22.1%\t23.9%\t23.3%\t24.7%\n",
      "22.8%\t20.0%\t23.9%\t22.0%\n",
      "21.1%\t25.6%\t23.2%\t24.6%\n",
      "19.6%\t24.2%\t22.5%\t23.0%\n",
      "26.0%\t21.1%\t25.4%\t23.3%\n",
      "25.3%\t20.0%\t25.8%\t22.8%\n",
      "26.7%\t21.8%\t25.7%\t23.7%\n",
      "18.6%\t24.9%\t23.2%\t25.5%\n",
      "23.5%\t22.5%\t25.3%\t21.0%\n",
      "27.4%\t20.0%\t25.2%\t24.8%\n",
      "19.6%\t24.9%\t20.6%\t24.9%\n",
      "21.8%\t21.4%\t23.5%\t24.3%\n",
      "23.9%\t20.4%\t25.1%\t23.3%\n",
      "20.0%\t24.6%\t22.5%\t25.0%\n",
      "24.9%\t24.2%\t25.1%\t24.1%\n",
      "23.5%\t22.8%\t23.8%\t25.5%\n",
      "25.6%\t24.6%\t24.9%\t22.7%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ewei/HCDM_Code/Experiment/FeatureSelection/FeatureSelection.ipynb Cell 6'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ewei/HCDM_Code/Experiment/FeatureSelection/FeatureSelection.ipynb#ch0000007?line=30'>31</a>\u001b[0m \u001b[39mfor\u001b[39;00m task_idx \u001b[39min\u001b[39;00m tasks:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ewei/HCDM_Code/Experiment/FeatureSelection/FeatureSelection.ipynb#ch0000007?line=31'>32</a>\u001b[0m     labels \u001b[39m=\u001b[39m FeatureMetrics\u001b[39m.\u001b[39mdiscretize(tasks[task_idx])\u001b[39m.\u001b[39mlong()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ewei/HCDM_Code/Experiment/FeatureSelection/FeatureSelection.ipynb#ch0000007?line=32'>33</a>\u001b[0m     base_g0, base_gX \u001b[39m=\u001b[39m runtrial(graph\u001b[39m.\u001b[39;49madj, labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ewei/HCDM_Code/Experiment/FeatureSelection/FeatureSelection.ipynb#ch0000007?line=33'>34</a>\u001b[0m     lock_g0, lock_gX \u001b[39m=\u001b[39m runtrial(locked_adj, labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ewei/HCDM_Code/Experiment/FeatureSelection/FeatureSelection.ipynb#ch0000007?line=34'>35</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mbase_g0\u001b[39m:\u001b[39;00m\u001b[39m.1%\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{\u001b[39;00mlock_g0\u001b[39m:\u001b[39;00m\u001b[39m.1%\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{\u001b[39;00mbase_gX\u001b[39m:\u001b[39;00m\u001b[39m.1%\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{\u001b[39;00mlock_gX\u001b[39m:\u001b[39;00m\u001b[39m.1%\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/Users/ewei/HCDM_Code/Experiment/FeatureSelection/FeatureSelection.ipynb Cell 6'\u001b[0m in \u001b[0;36mruntrial\u001b[0;34m(adj, labels)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ewei/HCDM_Code/Experiment/FeatureSelection/FeatureSelection.ipynb#ch0000007?line=4'>5</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ewei/HCDM_Code/Experiment/FeatureSelection/FeatureSelection.ipynb#ch0000007?line=5'>6</a>\u001b[0m \u001b[39mReturn the accuracy over g0 and gX of a GCN trained using adj with respect to labels\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ewei/HCDM_Code/Experiment/FeatureSelection/FeatureSelection.ipynb#ch0000007?line=6'>7</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ewei/HCDM_Code/Experiment/FeatureSelection/FeatureSelection.ipynb#ch0000007?line=7'>8</a>\u001b[0m model \u001b[39m=\u001b[39m GCN(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ewei/HCDM_Code/Experiment/FeatureSelection/FeatureSelection.ipynb#ch0000007?line=8'>9</a>\u001b[0m     input_features\u001b[39m=\u001b[39mgraph\u001b[39m.\u001b[39mfeatures\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ewei/HCDM_Code/Experiment/FeatureSelection/FeatureSelection.ipynb#ch0000007?line=9'>10</a>\u001b[0m     output_classes\u001b[39m=\u001b[39mlabels\u001b[39m.\u001b[39mmax()\u001b[39m.\u001b[39mitem() \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ewei/HCDM_Code/Experiment/FeatureSelection/FeatureSelection.ipynb#ch0000007?line=15'>16</a>\u001b[0m     name\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbaseline\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ewei/HCDM_Code/Experiment/FeatureSelection/FeatureSelection.ipynb#ch0000007?line=16'>17</a>\u001b[0m )\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ewei/HCDM_Code/Experiment/FeatureSelection/FeatureSelection.ipynb#ch0000007?line=18'>19</a>\u001b[0m model\u001b[39m.\u001b[39;49mfitManual(graph\u001b[39m.\u001b[39;49mfeatures, adj, labels, graph\u001b[39m.\u001b[39;49midx_train, graph\u001b[39m.\u001b[39;49midx_test, args\u001b[39m.\u001b[39;49mreg_epochs, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ewei/HCDM_Code/Experiment/FeatureSelection/FeatureSelection.ipynb#ch0000007?line=19'>20</a>\u001b[0m pred \u001b[39m=\u001b[39m model(graph\u001b[39m.\u001b[39mfeatures, adj)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ewei/HCDM_Code/Experiment/FeatureSelection/FeatureSelection.ipynb#ch0000007?line=20'>21</a>\u001b[0m acc_g0 \u001b[39m=\u001b[39m FeatureMetrics\u001b[39m.\u001b[39mcategorical_accuracy(labels[g0], pred[g0]\u001b[39m.\u001b[39margmax(\u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m~/HCDM_Code/Experiment/FeatureSelection/../../Models/GCN.py:55\u001b[0m, in \u001b[0;36mGCN.fitManual\u001b[0;34m(self, features, adj, labels, idx_train, idx_test, epochs, verbose)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/ewei/HCDM_Code/Experiment/FeatureSelection/../../Models/GCN.py?line=50'>51</a>\u001b[0m predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m(features, adj)\n\u001b[1;32m     <a href='file:///Users/ewei/HCDM_Code/Experiment/FeatureSelection/../../Models/GCN.py?line=52'>53</a>\u001b[0m loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mcross_entropy(predictions[idx_train], labels[idx_train])\n\u001b[0;32m---> <a href='file:///Users/ewei/HCDM_Code/Experiment/FeatureSelection/../../Models/GCN.py?line=54'>55</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='file:///Users/ewei/HCDM_Code/Experiment/FeatureSelection/../../Models/GCN.py?line=55'>56</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='file:///Users/ewei/HCDM_Code/Experiment/FeatureSelection/../../Models/GCN.py?line=56'>57</a>\u001b[0m t\u001b[39m.\u001b[39mset_postfix({\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mround\u001b[39m(loss\u001b[39m.\u001b[39mitem(), \u001b[39m2\u001b[39m)})\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/pygraph/lib/python3.9/site-packages/torch/_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/anaconda3/envs/pygraph/lib/python3.9/site-packages/torch/_tensor.py?line=297'>298</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///opt/homebrew/anaconda3/envs/pygraph/lib/python3.9/site-packages/torch/_tensor.py?line=298'>299</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    <a href='file:///opt/homebrew/anaconda3/envs/pygraph/lib/python3.9/site-packages/torch/_tensor.py?line=299'>300</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    <a href='file:///opt/homebrew/anaconda3/envs/pygraph/lib/python3.9/site-packages/torch/_tensor.py?line=300'>301</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/anaconda3/envs/pygraph/lib/python3.9/site-packages/torch/_tensor.py?line=304'>305</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    <a href='file:///opt/homebrew/anaconda3/envs/pygraph/lib/python3.9/site-packages/torch/_tensor.py?line=305'>306</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> <a href='file:///opt/homebrew/anaconda3/envs/pygraph/lib/python3.9/site-packages/torch/_tensor.py?line=306'>307</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/pygraph/lib/python3.9/site-packages/torch/autograd/__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/anaconda3/envs/pygraph/lib/python3.9/site-packages/torch/autograd/__init__.py?line=150'>151</a>\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/homebrew/anaconda3/envs/pygraph/lib/python3.9/site-packages/torch/autograd/__init__.py?line=151'>152</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m--> <a href='file:///opt/homebrew/anaconda3/envs/pygraph/lib/python3.9/site-packages/torch/autograd/__init__.py?line=153'>154</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(\n\u001b[1;32m    <a href='file:///opt/homebrew/anaconda3/envs/pygraph/lib/python3.9/site-packages/torch/autograd/__init__.py?line=154'>155</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    <a href='file:///opt/homebrew/anaconda3/envs/pygraph/lib/python3.9/site-packages/torch/autograd/__init__.py?line=155'>156</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "########################\n",
    "#region Evaluation\n",
    "\n",
    "def runtrial(adj, labels):\n",
    "    \"\"\"\n",
    "    Return the accuracy over g0 and gX of a GCN trained using adj with respect to labels\n",
    "    \"\"\"\n",
    "    model = GCN(\n",
    "        input_features=graph.features.shape[1],\n",
    "        output_classes=labels.max().item() + 1,\n",
    "        hidden_layers=args.hidden_layers,\n",
    "        device=device,\n",
    "        lr=args.model_lr,\n",
    "        dropout=args.dropout,\n",
    "        weight_decay=args.weight_decay,\n",
    "        name=f\"baseline\"\n",
    "    ).to(device)\n",
    "\n",
    "    model.fitManual(graph.features, adj, labels, graph.idx_train, graph.idx_test, args.reg_epochs, False)\n",
    "    pred = model(graph.features, adj)\n",
    "    acc_g0 = FeatureMetrics.categorical_accuracy(labels[g0], pred[g0].argmax(1))\n",
    "    acc_gX = FeatureMetrics.categorical_accuracy(labels[gX], pred[gX].argmax(1))\n",
    "\n",
    "    return acc_g0, acc_gX\n",
    "\n",
    "locked_adj = Utils.get_modified_adj(graph.adj, best)\n",
    "diff = locked_adj - graph.adj\n",
    "edges = int(diff.abs().sum().item())\n",
    "\n",
    "print(f\"b_g0\\tl_g0\\tb_gX\\tl_gX\")\n",
    "for task_idx in tasks:\n",
    "    labels = FeatureMetrics.discretize(tasks[task_idx]).long()\n",
    "    base_g0, base_gX = runtrial(graph.adj, labels)\n",
    "    lock_g0, lock_gX = runtrial(locked_adj, labels)\n",
    "    print(f\"{base_g0:.1%}\\t{lock_g0:.1%}\\t{base_gX:.1%}\\t{lock_gX:.1%}\")\n",
    "\n",
    "    row = {\n",
    "        \"seed\": args.seed,\n",
    "        \"dataset\": args.dataset,\n",
    "        \"protect_size\": args.protect_size,\n",
    "        \"reg_epochs\": args.reg_epochs,\n",
    "        \"ptb_epochs\": args.ptb_epochs,\n",
    "        \"ptb_rate\": args.ptb_rate,\n",
    "        \"ptb_sample_num\": args.num_samples,\n",
    "        \"ptb_sample_size\": args.sample_size,\n",
    "        \"task_idx\": task_idx,\n",
    "        \"base_g0\": base_g0,\n",
    "        \"base_gX\": base_gX,\n",
    "        \"lock_g0\": lock_g0,\n",
    "        \"lock_gX\": lock_gX,\n",
    "        \"rel_g0\": 1 - (lock_g0 / base_g0),\n",
    "        \"rel_gX\": 1 - (lock_gX / base_gX),\n",
    "        \"edges\": edges\n",
    "    }\n",
    "    \n",
    "    if args.save != 'N':\n",
    "        Export.saveData(args.save, row)\n",
    "\n",
    "#endregion\n",
    "########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "#region Evaluation\n",
    "\n",
    "from Utils import Export\n",
    "\n",
    "print(\"==== Evaluation ====\")\n",
    "print(f\"Task,\\tG0,\\tGX,\\tD_G0\\tD_GX\")\n",
    "\n",
    "locked_adj = Utils.get_modified_adj(graph.adj, best)\n",
    "diff = locked_adj - graph.adj\n",
    "\n",
    "for task_idx in range(selected_feat.shape[0]):\n",
    "    temp_labels = tasks[t][\"feat\"].long()\n",
    "    label_max = temp_labels.max().item() + 1\n",
    "\n",
    "    baseline_model = GCN(\n",
    "        input_features=graph.features.shape[1],\n",
    "        output_classes=label_max,\n",
    "        hidden_layers=args.hidden_layers,\n",
    "        device=device,\n",
    "        lr=args.model_lr,\n",
    "        dropout=args.dropout,\n",
    "        weight_decay=args.weight_decay,\n",
    "        name=f\"baseline\"\n",
    "    ).to(device)\n",
    "\n",
    "    baseline_model.fitManual(graph.features, graph.adj, temp_labels, graph.idx_train, graph.idx_test, args.reg_epochs, False)\n",
    "\n",
    "    pred = baseline_model(graph.features, graph.adj)\n",
    "    baseline_acc = Metrics.partial_acc(pred, temp_labels, g0, gX, False)\n",
    "\n",
    "\n",
    "    locked_model = GCN(\n",
    "        input_features=graph.features.shape[1],\n",
    "        output_classes=label_max,\n",
    "        hidden_layers=args.hidden_layers,\n",
    "        device=device,\n",
    "        lr=args.model_lr,\n",
    "        dropout=args.dropout,\n",
    "        weight_decay=args.weight_decay,\n",
    "        name=f\"locked\"\n",
    "    )\n",
    "\n",
    "    locked_model.fitManual(graph.features, locked_adj, temp_labels, graph.idx_train, graph.idx_test, args.reg_epochs, False)\n",
    "\n",
    "    pred = locked_model(graph.features, locked_adj)\n",
    "    locked_acc = Metrics.partial_acc(pred, temp_labels, g0, gX, False)\n",
    "\n",
    "    dg0 = locked_acc[\"g0\"] - baseline_acc[\"g0\"]\n",
    "    dgX = locked_acc[\"gX\"] - baseline_acc[\"gX\"]\n",
    "\n",
    "    print(f\"{t},\\t{dg0:.1%},\\t{dgX:.1%},\\t{tasks[t]['ent']:.2f},\\t{tasks[t]['corr']:.2f}\")\n",
    "\n",
    "    diffSummary = Metrics.show_metrics(diff, temp_labels, g0, device, False)\n",
    "\n",
    "    results = {\n",
    "        \"seed\": args.seed,\n",
    "        \"dataset\": args.dataset,\n",
    "        \"protect_size\": args.protect_size,\n",
    "        \"reg_epochs\": args.reg_epochs,\n",
    "        \"ptb_epochs\": args.ptb_epochs,\n",
    "        \"ptb_rate\": args.ptb_rate,\n",
    "        \"ptb_sample_num\": args.num_samples,\n",
    "        \"ptb_sample_size\": args.sample_size,\n",
    "        \"ratio_g0\": samplingMatrix.g0_ratio.item(),\n",
    "        \"ratio_gX\": samplingMatrix.gX_ratio.item(),\n",
    "        \"ratio_g0gX\": samplingMatrix.g0gX_ratio.item(),\n",
    "        \"feature\": t,\n",
    "        \"corr\": tasks[t][\"corr\"],\n",
    "        \"entropy\": tasks[t][\"ent\"],\n",
    "        \"base_g0\": baseline_acc[\"g0\"],\n",
    "        \"base_gX\": baseline_acc[\"gX\"],\n",
    "        \"d_g0\": dg0,\n",
    "        \"d_gX\": dgX,\n",
    "        \"edges\": int(diff.abs().sum().item()),\n",
    "    }\n",
    "\n",
    "    for add_remove in [\"add\", \"remove\"]:\n",
    "        for location in [\"g0\", \"gX\", \"g0gX\"]:\n",
    "            for similar in [\"same\", \"diff\"]:\n",
    "                results[\"_\".join([add_remove, location, similar])] = diffSummary[location][add_remove][similar]\n",
    "\n",
    "    Export.saveData(args.save_location, results)\n",
    "\n",
    "#endregion\n",
    "########################\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "284a17d5edba1b82bbb8793a64a3a9f6114640b8c8687fac297a1d74e5a299a9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pygraph')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
