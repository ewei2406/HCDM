{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fc4d8278cd0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--seed', type=int, default=123)\n",
    "parser.add_argument('--subgraph_size', type=int, default=64)\n",
    "parser.add_argument('--num_subgraphs', type=int, default=64)\n",
    "parser.add_argument('--batch_size', type=int, default=128)\n",
    "parser.add_argument('--file', type=str, default=\"./out.csv\")\n",
    "parser.add_argument('--dataset', type=str, default='cora', choices=[\n",
    "    'cora', 'citeseer', 'polblogs', 'pubmed'\n",
    "])\n",
    "parser.add_argument('--attack', type=str, default='pgd', choices=[\n",
    "    'meta', 'pgd', 'nettack'\n",
    "])\n",
    "parser.add_argument('--ptb_rate', type=float, default=0.25)\n",
    "\n",
    "# device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = 'cpu'\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset...\n",
      "Selecting 1 largest connected components\n"
     ]
    }
   ],
   "source": [
    "from deeprobust.graph.data import Dataset, PrePtbDataset, Dpr2Pyg\n",
    "from deeprobust.graph.utils import preprocess\n",
    "from numpy import ndarray\n",
    "\n",
    "clean_dataset = Dataset(root='./tmp/', name=args.dataset, seed=args.seed)\n",
    "adj, feat, labels = clean_dataset.adj, clean_dataset.features, clean_dataset.labels\n",
    "adj, feat, labels = preprocess(adj, feat, labels, preprocess_adj=False) # conver to tensor\n",
    "idx_train, idx_val, idx_test = clean_dataset.idx_train, clean_dataset.idx_val, clean_dataset.idx_test\n",
    "# adj = torch.tensor(clean_dataset.adj.toarray(), dtype=torch.float).to(device)\n",
    "# feat = torch.tensor(clean_dataset.features.toarray(), dtype=torch.float).to(device)\n",
    "# label = torch.tensor(clean_dataset.labels, dtype=torch.long).to(device)\n",
    "\n",
    "train_mask = torch.zeros([adj.shape[0]], dtype=torch.bool)  \n",
    "train_mask[idx_train] = 1\n",
    "test_mask = torch.zeros([adj.shape[0]], dtype=torch.bool)  \n",
    "test_mask[idx_test] = 1\n",
    "\n",
    "num_samples = 2560\n",
    "subgraph_size = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:09<00:00, 21.71it/s]\n"
     ]
    }
   ],
   "source": [
    "from deeprobust.graph.defense import GCN\n",
    "from deeprobust.graph.global_attack import PGDAttack\n",
    "\n",
    "# ptb_data = PrePtbDataset(root='./tmp/', name=args.dataset,\n",
    "#                                         attack_method='meta',\n",
    "#                                         ptb_rate=0.25) # here ptb_rate means number of perturbation per nodes\n",
    "\n",
    "# ptb_adj = torch.tensor(ptb_data.adj.toarray(), dtype=torch.float).to(device)\n",
    "\n",
    "victim_model = GCN(nfeat=feat.shape[1], nclass=labels.max().item()+1,\n",
    "                    nhid=16, dropout=0.5, weight_decay=5e-4, device=device).to(device)\n",
    "victim_model.fit(feat, adj, labels, idx_train)\n",
    "model = PGDAttack(model=victim_model, nnodes=adj.shape[0], loss_type='CE', device=device).to(device)\n",
    "model.attack(feat, adj, labels, idx_train, n_perturbations=adj.triu().sum() * 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== testing GCN on purified graph ===\n",
      "Test set results: loss= 0.9869 accuracy= 0.6771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6770623742454729"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcn = GCN(nfeat=feat.shape[1], nclass=labels.max().item()+1,\n",
    "                nhid=16, device=device).to(device)\n",
    "gcn.fit(feat, model.modified_adj, labels, idx_train, idx_val, patience=30)\n",
    "print('=== testing GCN on purified graph ===')\n",
    "gcn.test(idx_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import Sequential, DenseGCNConv\n",
    "from torch.nn import Linear, ReLU\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "def get_gcn(in_size, out_size, hid: int=64):\n",
    "    return Sequential('x, adj', [\n",
    "        (DenseGCNConv(in_size, hid), 'x, adj -> x'),\n",
    "        ReLU(inplace=True),\n",
    "        (DenseGCNConv(hid, hid), 'x, adj -> x'),\n",
    "        ReLU(inplace=True),\n",
    "        Linear(hid, out_size),\n",
    "        # Linear(hid, int(label.max()) + 1),\n",
    "    ]).to(device)\n",
    "\n",
    "def train(model, dataloader: DataLoader, epochs: int):\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), 1e-4)\n",
    "    t = tqdm(range(epochs), bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}')\n",
    "    t.set_description(\"Model training\")\n",
    "    loss = torch.tensor(0)\n",
    "    for _ in t:\n",
    "        for feats, adjs, labels, train_masks in dataloader:\n",
    "            pred = model(feats, adjs)\n",
    "            mask = train_masks.flatten()\n",
    "            loss = F.cross_entropy(pred.flatten(end_dim=1)[mask], labels.flatten(end_dim=1)[mask])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            t.set_postfix({\"loss\": round(loss.item(), 2)})\n",
    "\n",
    "def train_adj(model, feat, adj, label, train_mask, epochs: int):\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), 1e-4)\n",
    "    t = tqdm(range(epochs), bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}')\n",
    "    t.set_description(\"Model training\")\n",
    "    loss = torch.tensor(0)\n",
    "    for _ in t:\n",
    "        pred = model(feat, adj)\n",
    "        loss = F.cross_entropy(pred.squeeze()[train_mask], label[train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        t.set_postfix({\"loss\": round(loss.item(), 2)})\n",
    "\n",
    "def eval(model, test_mask, feat, adj, label, text=\"\"):\n",
    "    model.eval()\n",
    "    pred = model(feat, adj)\n",
    "    acc = ((pred.argmax(dim=2).squeeze() == label)[test_mask]).float().mean().item()\n",
    "    print(\"\")\n",
    "    print(text + f\"Accuracy: {acc: 0.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model training: 100%|██████████| 1000/1000 [00:02<00:00, 409.58it/s, loss=0]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy:  82.49%\n",
      "123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_gcn = get_gcn(feat.shape[1], int(label.max()) + 1)\n",
    "train_adj(baseline_gcn, feat, adj, label, train_mask, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy:  82.49%\n"
     ]
    }
   ],
   "source": [
    "eval(baseline_gcn, test_mask, feat, adj, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model training: 100%|██████████| 1000/1000 [00:02<00:00, 418.76it/s, loss=0.45]\n"
     ]
    }
   ],
   "source": [
    "ptb_gcn = get_gcn(feat.shape[1], int(label.max()) + 1)\n",
    "train_adj(ptb_gcn, feat, ptb_adj, label, train_mask, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy:  34.31%\n"
     ]
    }
   ],
   "source": [
    "eval(ptb_gcn, test_mask, feat, adj, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_neighbor_subgraphs(adj: torch.Tensor, size: int, n: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Returns a tensor ~ `(n * size)` of node indices for `n` supgraphs of size `size`\n",
    "    \"\"\"\n",
    "    res = torch.zeros([n, size], dtype=torch.long)\n",
    "\n",
    "    for i in range(n):\n",
    "        out = []\n",
    "        stack = [random.randint(0, adj.shape[0] - 1)]\n",
    "        while len(out) < size:\n",
    "            if len(stack) == 0:\n",
    "                stack.append(random.randint(0, adj.shape[0] - 1))\n",
    "            curNode = stack.pop()\n",
    "            if curNode not in out:\n",
    "                out.append(curNode)\n",
    "                children = adj[curNode].nonzero().t()[0].cpu().tolist()\n",
    "                stack = children + stack\n",
    "        res[i] = torch.tensor(out)\n",
    "\n",
    "    return res\n",
    "\n",
    "subgraph_ids = get_neighbor_subgraphs(torch.tensor(ptb_data.adj.toarray()), 64, num_samples)\n",
    "\n",
    "temp = adj[subgraph_ids]\n",
    "subgraph_feats = feat[subgraph_ids]\n",
    "subgraph_adjs = torch.zeros(num_samples, subgraph_size, subgraph_size).to(device)\n",
    "# subgraph_adjs_pgd = torch.zeros(num_samples, subgraph_size, subgraph_size).to(device)\n",
    "subgraph_labels = label[subgraph_ids]\n",
    "subgraph_train_masks = train_mask[subgraph_ids]\n",
    "for i in range(num_samples):\n",
    "    subgraph_adjs[i] = temp[i][:,subgraph_ids[i]]\n",
    "\n",
    "temp = ptb_adj[subgraph_ids]\n",
    "subgraph_adjs_pgd = torch.zeros(num_samples, subgraph_size, subgraph_size).to(device)\n",
    "for i in range(num_samples):\n",
    "    subgraph_adjs_pgd[i] = temp[i][:,subgraph_ids[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model training: 100%|██████████| 100/100 [00:04<00:00, 23.12it/s, loss=0]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy:  81.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "clean_dataloader = DataLoader(\n",
    "    TensorDataset(subgraph_feats, subgraph_adjs, subgraph_labels, subgraph_train_masks), \n",
    "    batch_size=256, shuffle=True)\n",
    "\n",
    "clean_subgraphs_gcn = get_gcn(feat.shape[1], int(label.max()) + 1)\n",
    "train(clean_subgraphs_gcn, clean_dataloader, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy:  81.99%\n"
     ]
    }
   ],
   "source": [
    "eval(clean_subgraphs_gcn, test_mask, feat, adj, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model training: 100%|██████████| 200/200 [00:24<00:00,  8.14it/s, loss=0.23]\n"
     ]
    }
   ],
   "source": [
    "pgd_dataloader = DataLoader(\n",
    "    TensorDataset(subgraph_feats, subgraph_adjs_pgd, subgraph_labels, subgraph_train_masks),\n",
    "    batch_size=1024, shuffle=True)\n",
    "\n",
    "ptb_gcn_samples = get_gcn(feat.shape[1], int(label.max()) + 1)\n",
    "train(ptb_gcn_samples, pgd_dataloader, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy:  64.94%\n"
     ]
    }
   ],
   "source": [
    "eval(ptb_gcn_samples, test_mask, feat, adj, label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_c116",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
