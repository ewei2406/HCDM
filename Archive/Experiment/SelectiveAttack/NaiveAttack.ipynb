{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Environment ====\n",
      "  torch version: 1.9.0\n",
      "  device: cuda\n",
      "  torch seed: 123\n",
      "==== Dataset: cora ====\n",
      "Loading cora dataset...\n",
      "\n",
      "[i] Dataset Summary: \n",
      "\tadj shape: [2708, 2708]\n",
      "\tfeature shape: [2708, 1433]\n",
      "\tnum labels: 7\n",
      "\tsplit seed: 123\n",
      "\ttrain|val|test: 140|500|1000\n",
      "Number of protected nodes: 285\n",
      "Protected Size: 10.52%\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join('../..'))\n",
    "\n",
    "################################################\n",
    "# Arguments\n",
    "################################################\n",
    "\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--seed', type=int, default=123, help='Random seed for model')\n",
    "parser.add_argument('--gpu', type=int, default=0, help='gpu')\n",
    "\n",
    "parser.add_argument('--model_lr', type=float, default=0.01, help='Initial learning rate')\n",
    "parser.add_argument('--weight_decay', type=float, default=5e-4, help='Weight decay (L2 loss on parameters)')\n",
    "parser.add_argument('--hidden_layers', type=int, default=32, help='Number of hidden layers')\n",
    "parser.add_argument('--dropout', type=float, default=0.5, help='Dropout rate for GCN')\n",
    "\n",
    "parser.add_argument('--protect_size', type=float, default=0.1, help='Number of randomly chosen protected nodes')\n",
    "parser.add_argument('--ptb_rate', type=float, default=0.25, help='Perturbation rate (percentage of available edges)')\n",
    "\n",
    "# simplistic1, simplistic2, noise, SLLnoSample, SLL\n",
    "parser.add_argument('--method', type=str, default='SLL', help='method')\n",
    "parser.add_argument('--do_sampling', type=str, default='Y', help='to do sampling or not')\n",
    "parser.add_argument('--sample_size', type=int, default=500, help='')\n",
    "parser.add_argument('--num_samples', type=int, default=20, help='')\n",
    "\n",
    "\n",
    "parser.add_argument('--reg_epochs', type=int, default=100, help='Epochs to train models')\n",
    "parser.add_argument('--ptb_epochs', type=int, default=30, help='Epochs to perturb adj matrix')\n",
    "parser.add_argument('--surrogate_epochs', type=int, default=0, help='Epochs to train surrogate before perturb')\n",
    "\n",
    "parser.add_argument('--save', type=str, default='N', help='save the outputs to csv')\n",
    "parser.add_argument('--save_location', type=str, default=\"./SelectiveAttack.csv\", help='where to save the outputs to csv')\n",
    "parser.add_argument('--dataset', type=str, default='cora', help='dataset')\n",
    "\n",
    "\n",
    "parser.add_argument('--check_universal', type=str, default='N', help='check universal protection')\n",
    "\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "################################################\n",
    "# Environment\n",
    "################################################\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(f'cuda:{args.gpu}' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "if device != 'cpu':\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "print('==== Environment ====')\n",
    "print(f'  torch version: {torch.__version__}')\n",
    "print(f'  device: {device}')\n",
    "print(f'  torch seed: {args.seed}')\n",
    "\n",
    "################################################\n",
    "# Dataset\n",
    "################################################\n",
    "\n",
    "from Utils import GraphData\n",
    "\n",
    "print(f'==== Dataset: {args.dataset} ====')\n",
    "\n",
    "graph = GraphData.getGraph(\"../../Datasets\", args.dataset, \"gcn\", args.seed, device)\n",
    "graph.summarize()\n",
    "\n",
    "################################################\n",
    "# Designate protected\n",
    "################################################\n",
    "\n",
    "g0 = torch.rand(graph.features.shape[0]) <= args.protect_size\n",
    "# g0 = graph.labels == 5 \n",
    "g0 = g0.to(device)\n",
    "gX = ~g0\n",
    "\n",
    "print(f\"Number of protected nodes: {g0.sum():.0f}\")\n",
    "print(f\"Protected Size: {g0.sum() / graph.features.shape[0]:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.method == 'SLL':\n",
    "  ################################################\n",
    "  # Sampling Matrix\n",
    "  ################################################\n",
    "\n",
    "  from SamplingMatrix import SamplingMatrix\n",
    "\n",
    "  samplingMatrix = SamplingMatrix(g0, gX, graph.adj, args.sample_size)\n",
    "\n",
    "  samplingMatrix.get_sample()\n",
    "  samplingMatrix.getRatio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing: 100%|██████████| 30/30 [00:08<00:00,  3.37it/s, adj_l=2.83, adj_g=-2, pre-p=1319, target=1319, loss=tensor(2.8293, device='cuda:0', grad_fn=<SubBackward0>)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best sample loss: 1.50\t Edges: 1307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if args.method == 'SLL':\n",
    "  ################################################\n",
    "  # Sampling Matrix\n",
    "  ################################################\n",
    "\n",
    "  from SamplingMatrix import SamplingMatrix\n",
    "\n",
    "  samplingMatrix = SamplingMatrix(g0, gX, graph.adj, args.sample_size)\n",
    "\n",
    "  samplingMatrix.get_sample()\n",
    "  samplingMatrix.getRatio()\n",
    "\n",
    "# %%\n",
    "################################################\n",
    "# Generate Perturbations (RANDOM NOISE)\n",
    "################################################\n",
    "import Utils.Utils as Utils\n",
    "import torch.nn.functional as F\n",
    "\n",
    "if args.method == 'noise':\n",
    "  noise = torch.zeros_like(graph.adj)\n",
    "  noise.index_fill_(0, Utils.bool_to_idx(gX).squeeze(), 1)\n",
    "  noise.index_fill_(1, Utils.bool_to_idx(gX).squeeze(), 1)\n",
    "  noise = torch.ones_like(noise) - noise\n",
    "  noise = noise * (graph.adj.sum() * args.ptb_rate / noise.sum())\n",
    "  best = torch.bernoulli(noise)\n",
    "  locked_adj = Utils.get_modified_adj(graph.adj, best)\n",
    "elif args.method == 'simplistic1':\n",
    "  mask = torch.zeros_like(graph.adj)\n",
    "  mask.index_fill_(0, Utils.bool_to_idx(gX).squeeze(), 1)\n",
    "  mask.index_fill_(1, Utils.bool_to_idx(gX).squeeze(), 1)\n",
    "  mask = 1 - mask\n",
    "  locked_adj = graph.adj - mask\n",
    "  locked_adj = locked_adj.clamp(0, 1)\n",
    "elif args.method == 'simplistic2':\n",
    "  locked_adj = graph.adj.clone()\n",
    "  locked_adj.index_fill_(0, Utils.bool_to_idx(g0).squeeze(), 0)\n",
    "  locked_adj.index_fill_(1, Utils.bool_to_idx(g0).squeeze(), 0)\n",
    "else:\n",
    "  from Models.GCN import GCN\n",
    "\n",
    "  surrogate = GCN(\n",
    "      input_features=graph.features.shape[1],\n",
    "      output_classes=graph.labels.max().item()+1,\n",
    "      hidden_layers=args.hidden_layers,\n",
    "      device=device,\n",
    "      lr=args.model_lr,\n",
    "      dropout=args.dropout,\n",
    "      weight_decay=args.weight_decay,\n",
    "      name=f\"surrogate\"\n",
    "  ).to(device)\n",
    "\n",
    "  import torch.nn.functional as F\n",
    "  from tqdm import tqdm\n",
    "\n",
    "  perturbations = torch.zeros_like(graph.adj).float()\n",
    "  count = torch.zeros_like(graph.adj).float()\n",
    "  num_perturbations = args.ptb_rate * graph.adj.sum()\n",
    "\n",
    "  t = tqdm(range(args.ptb_epochs), bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}')\n",
    "  t.set_description(\"Perturbing\")\n",
    "\n",
    "  for epoch in t:\n",
    "    # Re-initialize adj_grad\n",
    "    adj_grad = torch.zeros_like(graph.adj).float()\n",
    "\n",
    "    # Get modified adj\n",
    "    modified_adj = Utils.get_modified_adj(graph.adj, perturbations).float().to(device)\n",
    "\n",
    "    if args.method == 'SLL':\n",
    "\n",
    "      for sample_epoch in range(args.num_samples):\n",
    "        # Get sample indices\n",
    "        # sampled = torch.bernoulli(sampling_matrix)\n",
    "        idx = samplingMatrix.get_sample()\n",
    "        # print(idx)\n",
    "\n",
    "        # Map sample to adj\n",
    "        sample = modified_adj[idx[0], idx[1]].clone().detach().requires_grad_(True).to(device)\n",
    "        modified_adj[idx[0], idx[1]] = sample\n",
    "\n",
    "        # Get grad\n",
    "        predictions = surrogate(graph.features, modified_adj)\n",
    "        loss = F.cross_entropy(predictions[g0], graph.labels[g0]) \\\n",
    "            - F.cross_entropy(predictions[gX], graph.labels[gX])\n",
    "\n",
    "        grad = torch.autograd.grad(loss, sample)[0]\n",
    "\n",
    "        # Implement averaging\n",
    "        adj_grad[idx[0], idx[1]] += grad\n",
    "        count[idx[0], idx[1]] += 1\n",
    "\n",
    "        # Update the sampling matrix\n",
    "        samplingMatrix.updateByGrad(adj_grad, count)\n",
    "        samplingMatrix.getRatio()\n",
    "\n",
    "        # Average the gradient\n",
    "        adj_grad = torch.div(adj_grad, count)\n",
    "        adj_grad[adj_grad != adj_grad] = 0\n",
    "    \n",
    "    else:\n",
    "      # Get grad\n",
    "      modified_adj = modified_adj.clone().detach().requires_grad_(True).to(device)\n",
    "      predictions = surrogate(graph.features, modified_adj)\n",
    "      loss = F.cross_entropy(predictions[g0], graph.labels[g0]) \\\n",
    "          - F.cross_entropy(predictions[gX], graph.labels[gX])\n",
    "\n",
    "      adj_grad = torch.autograd.grad(loss, modified_adj)[0]\n",
    "\n",
    "    # Update perturbations\n",
    "    lr = (num_perturbations) / (epoch + 1)\n",
    "    pre_projection = int(perturbations.sum() / 2)\n",
    "    perturbations = perturbations + (lr * adj_grad)\n",
    "    perturbations = Utils.projection(perturbations, num_perturbations)\n",
    "\n",
    "    # Train the model\n",
    "    modified_adj = Utils.get_modified_adj(graph.adj, perturbations)\n",
    "    surrogate.train1epoch(graph.features, modified_adj, graph.labels, graph.idx_train, graph.idx_test)\n",
    "\n",
    "    t.set_postfix({\"adj_l\": loss.item(),\n",
    "                    \"adj_g\": int(adj_grad.sum()),\n",
    "                    \"pre-p\": pre_projection,\n",
    "                    \"target\": int(num_perturbations / 2),\n",
    "                    \"loss\": loss})\n",
    "\n",
    "  with torch.no_grad(): \n",
    "    max_loss = -1000\n",
    "    for k in range(0,3):\n",
    "      sample = torch.bernoulli(perturbations)\n",
    "      modified_adj = Utils.get_modified_adj(graph.adj, perturbations)\n",
    "      modified_adj = Utils.make_symmetric(modified_adj) # Removing this creates \"impossible\" adj, but works well\n",
    "\n",
    "      predictions = surrogate(graph.features, modified_adj) \n",
    "\n",
    "      loss = F.cross_entropy(predictions[g0], graph.labels[g0]) \\\n",
    "          - F.cross_entropy(predictions[gX], graph.labels[gX])\n",
    "\n",
    "      if loss > max_loss:\n",
    "        max_loss = loss\n",
    "        best = sample\n",
    "        best_mod = modified_adj\n",
    "    \n",
    "    print(f\"Best sample loss: {loss:.2f}\\t Edges: {best.abs().sum() / 2:.0f}\")\n",
    "    \n",
    "    locked_adj = Utils.get_modified_adj(graph.adj, best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(10556, device='cuda:0'), tensor(10386, device='cuda:0'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.adj.sum(), locked_adj.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training baseline: 100%|██████████| 100/100 [00:00<00:00, 141.71it/s, loss=0.02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G0: 73.33%\n",
      "GX: 76.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training locked: 100%|██████████| 100/100 [00:00<00:00, 143.29it/s, loss=0.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G0: 25.26%\n",
      "GX: 75.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training baseline: 100%|██████████| 100/100 [00:00<00:00, 136.81it/s, loss=0.02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G0: 77.89%\n",
      "GX: 78.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training locked: 100%|██████████| 100/100 [00:00<00:00, 141.85it/s, loss=0.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G0: 25.96%\n",
      "GX: 74.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training baseline: 100%|██████████| 100/100 [00:00<00:00, 171.59it/s, loss=0.02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G0: 76.14%\n",
      "GX: 78.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training locked: 100%|██████████| 100/100 [00:00<00:00, 140.99it/s, loss=0.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G0: 25.61%\n",
      "GX: 73.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training baseline: 100%|██████████| 100/100 [00:00<00:00, 154.24it/s, loss=0.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G0: 74.39%\n",
      "GX: 76.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training locked: 100%|██████████| 100/100 [00:00<00:00, 153.86it/s, loss=0.02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G0: 27.02%\n",
      "GX: 72.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training baseline: 100%|██████████| 100/100 [00:00<00:00, 137.52it/s, loss=0.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G0: 77.19%\n",
      "GX: 79.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training locked: 100%|██████████| 100/100 [00:00<00:00, 137.37it/s, loss=0.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G0: 27.02%\n",
      "GX: 75.32%\n",
      "==== Accuracies ====\n",
      "         ΔG0\tΔGX\n",
      "task1 | -65.5%\t-4.6%\n",
      "     Within G0 ====\n",
      "                A-A\tA-B\tTOTAL\n",
      "          (+)   59  \t385  \t444\n",
      "          (-)   0  \t0  \t0\n",
      "     Within GX ====\n",
      "                A-A\tA-B\tTOTAL\n",
      "          (+)   89  \t252  \t341\n",
      "          (-)   0  \t0  \t0\n",
      "     Between G0-GX ====\n",
      "                A-A\tA-B\tTOTAL\n",
      "          (+)   85  \t1744  \t1829\n",
      "          (-)   0  \t0  \t0\n",
      "\n",
      "        TOTAL   233  \t2381  \t2614\n",
      "{'g0': {'add': {'same': 59, 'diff': 385, 'total': 444}, 'remove': {'same': 0, 'diff': 0, 'total': 0}, 'total': 444}, 'gX': {'add': {'same': 89, 'diff': 252, 'total': 341}, 'remove': {'same': 0, 'diff': 0, 'total': 0}, 'total': 341}, 'g0gX': {'add': {'same': 85, 'diff': 1744, 'total': 1829}, 'remove': {'same': 0, 'diff': 0, 'total': 0}, 'total': 1829}}\n"
     ]
    }
   ],
   "source": [
    "# locked_adj\n",
    "\n",
    "################################################\n",
    "# Evaluation\n",
    "################################################\n",
    "from Models.GCN import GCN\n",
    "import Utils.Metrics as Metrics\n",
    "\n",
    "dg0 = 0\n",
    "dgX = 0\n",
    "n = 5\n",
    "\n",
    "for k in range(n):\n",
    "\n",
    "    baseline_model = GCN(\n",
    "        input_features=graph.features.shape[1],\n",
    "        output_classes=graph.labels.max().item()+1,\n",
    "        hidden_layers=args.hidden_layers,\n",
    "        device=device,\n",
    "        lr=args.model_lr,\n",
    "        dropout=args.dropout,\n",
    "        weight_decay=args.weight_decay,\n",
    "        name=f\"baseline\"\n",
    "    ).to(device)\n",
    "\n",
    "    baseline_model.fit(graph, args.reg_epochs)\n",
    "\n",
    "    pred = baseline_model(graph.features, graph.adj)\n",
    "    baseline_acc = Metrics.partial_acc(pred, graph.labels, g0, gX)\n",
    "\n",
    "    locked_model = GCN(\n",
    "        input_features=graph.features.shape[1],\n",
    "        output_classes=graph.labels.max().item()+1,\n",
    "        hidden_layers=args.hidden_layers,\n",
    "        device=device,\n",
    "        lr=args.model_lr,\n",
    "        dropout=args.dropout,\n",
    "        weight_decay=args.weight_decay,\n",
    "        name=f\"locked\"\n",
    "    )\n",
    "\n",
    "    locked_model.fitManual(graph.features, locked_adj, graph.labels, graph.idx_train, graph.idx_test, args.reg_epochs)\n",
    "\n",
    "    pred = locked_model(graph.features, locked_adj)\n",
    "    locked_acc = Metrics.partial_acc(pred, graph.labels, g0, gX)\n",
    "\n",
    "    # base_g0 += baseline_acc[\"g0\"]\n",
    "    # base_gX += baseline_acc[\"gX\"]\n",
    "    # lock_g0 += locked_acc[\"g0\"]\n",
    "    # lock_gX += locked_acc[\"gX\"]\n",
    "\n",
    "    dg0 += ((locked_acc[\"g0\"] / baseline_acc[\"g0\"]) - 1) / n\n",
    "    dgX += ((locked_acc[\"gX\"] / baseline_acc[\"gX\"]) - 1) / n\n",
    "\n",
    "\n",
    "################################################\n",
    "# Summarize\n",
    "################################################\n",
    "\n",
    "# dg0 = ((lock_g0 / base_g0) - 1) / n\n",
    "# dgX = ((lock_gX / base_gX) - 1) / n\n",
    "\n",
    "print(\"==== Accuracies ====\")\n",
    "print(f\"         ΔG0\\tΔGX\")\n",
    "print(f\"task1 | {dg0:.1%}\\t{dgX:.1%}\")\n",
    "\n",
    "diff = locked_adj - graph.adj\n",
    "diffSummary = Metrics.show_metrics(diff, graph.labels, g0, device)\n",
    "\n",
    "print(diffSummary)\n",
    "\n",
    "################################################\n",
    "# Save\n",
    "################################################\n",
    "\n",
    "import Utils.Export as Export\n",
    "\n",
    "def getDiff(location, changeType):\n",
    "    loc = diffSummary[location][changeType]\n",
    "    dH = loc[\"same\"] - loc[\"diff\"]\n",
    "    return dH\n",
    "\n",
    "results = {\n",
    "    \"seed\": args.seed,\n",
    "    \"method\": args.method,\n",
    "    \"dataset\": args.dataset,\n",
    "    \"protect_size\": args.protect_size,\n",
    "    \"reg_epochs\": args.reg_epochs,\n",
    "    \"ptb_epochs\": args.ptb_epochs,\n",
    "    \"ptb_rate\": args.ptb_rate,\n",
    "    \"ptb_sample_num\": args.num_samples,\n",
    "    \"ptb_sample_size\": args.sample_size,\n",
    "    # \"ratio_g0\": samplingMatrix.g0_ratio.item(),\n",
    "    # \"ratio_gX\": samplingMatrix.gX_ratio.item(),\n",
    "    # \"ratio_g0gX\": samplingMatrix.g0gX_ratio.item(),\n",
    "    \"base_g0\": baseline_acc[\"g0\"],\n",
    "    \"base_gX\": baseline_acc[\"gX\"],\n",
    "    \"d_g0\": dg0,\n",
    "    \"d_gX\": dgX,\n",
    "    \"edges\": diff.abs().sum().item(),\n",
    "    \"dH_g0\": getDiff(\"g0\", \"add\") - getDiff(\"g0\", \"remove\"),\n",
    "    \"dH_gX\": getDiff(\"gX\", \"add\") - getDiff(\"gX\", \"remove\"),\n",
    "    \"dH_g0gX\": getDiff(\"g0gX\", \"add\") - getDiff(\"g0gX\", \"remove\"),\n",
    "}\n",
    "\n",
    "Export.saveData('./baseTrials.csv', results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pygraph')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a38a3b595fc6f4bb38b67d61493a288b49ae2ed3e9a2b5c1361925b2354e393"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
