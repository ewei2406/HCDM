{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from model import Grace\n",
    "from aug import aug\n",
    "from dataset import load\n",
    "\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "\n",
    "from eval import label_classification, eval_unbiasedness_movielens\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum([np.prod(p.size()) for p in model.parameters() if p.requires_grad])\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataname', type=str, default='Blogcatalog')\n",
    "parser.add_argument('--gpu', type=int, default=1)\n",
    "parser.add_argument('--split', type=str, default='random')\n",
    "parser.add_argument('--debias_method', type=str, default='uge-w', choices=['uge-r', 'uge-w', 'uge-c', 'none'], help='debiasing method to apply')\n",
    "parser.add_argument('--debias_attr', type=str, default='age', help='sensitive attribute to be debiased')\n",
    "parser.add_argument('--reg_weight', type=float, default=0.2, help='weight for the regularization based debiasing term')  \n",
    "\n",
    "parser.add_argument('--epochs', type=int, default=100, help='Number of training periods.')\n",
    "parser.add_argument('--lr', type=float, default=0.001, help='Learning rate.')\n",
    "parser.add_argument('--wd', type=float, default=1e-5, help='Weight decay.')\n",
    "parser.add_argument('--temp', type=float, default=1.0, help='Temperature.')\n",
    "\n",
    "parser.add_argument('--act_fn', type=str, default='relu')\n",
    "\n",
    "parser.add_argument(\"--hid_dim\", type=int, default=256, help='Hidden layer dim.')\n",
    "parser.add_argument(\"--out_dim\", type=int, default=256, help='Output layer dim.')\n",
    "\n",
    "parser.add_argument(\"--num_layers\", type=int, default=2, help='Number of GNN layers.')\n",
    "parser.add_argument('--der1', type=float, default=0.2, help='Drop edge ratio of the 1st augmentation.')\n",
    "parser.add_argument('--der2', type=float, default=0.2, help='Drop edge ratio of the 2nd augmentation.')\n",
    "parser.add_argument('--dfr1', type=float, default=0.2, help='Drop feature ratio of the 1st augmentation.')\n",
    "parser.add_argument('--dfr2', type=float, default=0.2, help='Drop feature ratio of the 2nd augmentation.')\n",
    "\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "if args.gpu != -1 and th.cuda.is_available():\n",
    "    args.device = 'cuda:{}'.format(args.gpu)\n",
    "else:\n",
    "    args.device = 'cpu'\n",
    "\n",
    "# Step 1: Load hyperparameters =================================================================== #\n",
    "lr = args.lr\n",
    "hid_dim = args.hid_dim\n",
    "out_dim = args.out_dim\n",
    "\n",
    "num_layers = args.num_layers\n",
    "act_fn = ({'relu': nn.ReLU(), 'prelu': nn.PReLU()})[args.act_fn]\n",
    "\n",
    "drop_edge_rate_1 = args.der1\n",
    "drop_edge_rate_2 = args.der2\n",
    "drop_feature_rate_1 = args.dfr1\n",
    "drop_feature_rate_2 = args.dfr2\n",
    "\n",
    "temp = args.temp\n",
    "epochs = args.epochs\n",
    "wd = args.wd\n",
    "debias_method = args.debias_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Dataset: Blogcatalog ====\n",
      "Loading blogcatalog dataset...\n",
      "\n",
      "[i] Dataset Summary: \n",
      "\tadj shape: [5196, 5196]\n",
      "\tfeature shape: [5196, 8189]\n",
      "\tnum labels: 6\n",
      "\tsplit seed: 100\n",
      "\ttrain|val|test: 120|500|1000\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "triu(): argument 'input' (position 1) must be Tensor, not method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/u/nyw6dh/HCDM/Experiment/Fair_GRACE/test copy.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhcdmg2.cs.virginia.edu/u/nyw6dh/HCDM/Experiment/Fair_GRACE/test%20copy.ipynb#ch0000013vscode-remote?line=16'>17</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdgl\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhcdmg2.cs.virginia.edu/u/nyw6dh/HCDM/Experiment/Fair_GRACE/test%20copy.ipynb#ch0000013vscode-remote?line=17'>18</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mUtils\u001b[39;00m \u001b[39mimport\u001b[39;00m Utils\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bhcdmg2.cs.virginia.edu/u/nyw6dh/HCDM/Experiment/Fair_GRACE/test%20copy.ipynb#ch0000013vscode-remote?line=18'>19</a>\u001b[0m edges \u001b[39m=\u001b[39m Utils\u001b[39m.\u001b[39;49mto_edges(graph\u001b[39m.\u001b[39;49madj)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhcdmg2.cs.virginia.edu/u/nyw6dh/HCDM/Experiment/Fair_GRACE/test%20copy.ipynb#ch0000013vscode-remote?line=19'>20</a>\u001b[0m graph \u001b[39m=\u001b[39m dgl\u001b[39m.\u001b[39mgraph((edges[\u001b[39m0\u001b[39m], edges[\u001b[39m1\u001b[39m]))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhcdmg2.cs.virginia.edu/u/nyw6dh/HCDM/Experiment/Fair_GRACE/test%20copy.ipynb#ch0000013vscode-remote?line=20'>21</a>\u001b[0m graph\u001b[39m.\u001b[39mndata[\u001b[39m'\u001b[39m\u001b[39mfeat\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m raw_graph\u001b[39m.\u001b[39mfeatures[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/HCDM/Experiment/Fair_GRACE/../../Utils/Utils.py:37\u001b[0m, in \u001b[0;36mto_edges\u001b[0;34m(adj)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_edges\u001b[39m(adj):\n\u001b[1;32m     34\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39m    Converts an adjacency matrix to a list of edges\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m     res \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtriu(adj)\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mnonzero()\u001b[39m.\u001b[39mpermute(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[1;32m     38\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n",
      "\u001b[0;31mTypeError\u001b[0m: triu(): argument 'input' (position 1) must be Tensor, not method"
     ]
    }
   ],
   "source": [
    "# Step 2: Prepare data =================================================================== #\n",
    "if debias_method in ['uge-w', 'uge-c']:\n",
    "    dataset = '{}_debias_{}'.format(args.dataname, args.debias_attr)\n",
    "else:\n",
    "    dataset = args.dataname\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join('../..'))\n",
    "from Utils import GraphData\n",
    "\n",
    "print(f'==== Dataset: {args.dataname} ====')\n",
    "\n",
    "raw_graph = GraphData.getGraph(\"../../Datasets\", args.dataname, \"gcn\", 100, args.device)\n",
    "raw_graph.summarize()\n",
    "\n",
    "\n",
    "# in_dim = graph.ndata['feat'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=5196, num_edges=171743,\n",
       "      ndata_schemes={'feat': Scheme(shape=(8188,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'sensitive_attr': Scheme(shape=(), dtype=torch.float32)}\n",
       "      edata_schemes={})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dgl\n",
    "from Utils import Utils\n",
    "edges = Utils.to_edges(raw_graph.adj)\n",
    "graph = dgl.graph((edges[0], edges[1]))\n",
    "\n",
    "graph.ndata['feat'] = raw_graph.features[:, 1:]\n",
    "graph.ndata['label'] = raw_graph.labels\n",
    "graph.ndata['sensitive_attr'] = raw_graph.features[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group finished.\n",
      "  attr_comb_group_num: 306\n",
      "  nobias_attr_comb_group_num: 306\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "SENSITIVE_ATTR_DICT = {\n",
    "    'movielens': ['gender', 'occupation', 'age'],\n",
    "    'pokec': ['gender', 'region', 'AGE'],\n",
    "    'pokec-z': ['gender', 'region', 'AGE'],\n",
    "    'pokec-n': ['gender', 'region', 'AGE'],\n",
    "}\n",
    "# Group nodes\n",
    "debias_attr = args.debias_attr\n",
    "attribute_list = SENSITIVE_ATTR_DICT[args.dataname]\n",
    "\n",
    "non_sens_attr_ls = [attr for attr in attribute_list if attr!=debias_attr]\n",
    "non_sens_attr_idx = [i for i in range(len(attribute_list)) if attribute_list[i]!=debias_attr]\n",
    "\n",
    "attribute_file = '{}/{}_node_attribute.csv'.format(DATA_FOLDER, args.dataname)\n",
    "node_attributes = pd.read_csv(attribute_file)\n",
    "\n",
    "attr_comb_groups = node_attributes.groupby(attribute_list)\n",
    "nobias_comb_groups = node_attributes.groupby(non_sens_attr_ls)\n",
    "\n",
    "attr_comb_groups_map = {tuple(group[1].iloc[0]):list(group[1].index) \n",
    "                        for group in attr_comb_groups}\n",
    "nobias_attr_comb_groups_map = {tuple(group[1].iloc[0][non_sens_attr_ls]):list(group[1].index) \n",
    "                            for group in nobias_comb_groups}\n",
    "\n",
    "print ('Group finished.')\n",
    "print ('  attr_comb_group_num:', len(attr_comb_groups_map.keys()))\n",
    "print ('  nobias_attr_comb_group_num:', len(nobias_attr_comb_groups_map.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_tuple(x, index_ls):\n",
    "  return tuple([x[idx] for idx in index_ls])\n",
    "\n",
    "def mem_eff_matmul_mean(mtx1, mtx2):\n",
    "  mtx1_rows = list(mtx1.shape)[0]\n",
    "  if mtx1_rows <= 1000:\n",
    "    return th.mean(th.matmul(mtx1, mtx2))\n",
    "  else:\n",
    "    value_sum = 0\n",
    "    for i in range(mtx1_rows // 1000):\n",
    "      value_sum += th.sum(th.matmul(mtx1[i*1000:(i+1)*1000, :], mtx2))\n",
    "    if mtx1_rows % 1000 != 0:\n",
    "      value_sum += th.sum(th.matmul(mtx1[(i+1)*1000:, :], mtx2))\n",
    "    return value_sum / (list(mtx1.shape)[0] * list(mtx2.shape)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1100663.)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.adj().coalesce().values().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(998543.5000), tensor(651270.1250))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_edge_num = graph.num_edges() * (1 - 0.1)\n",
    "expected_edges = graph.edata['weight'].sum()\n",
    "\n",
    "new_weights = (graph.edata['weight'] * target_edge_num / expected_edges).clamp(0,1)\n",
    "# graph.adj() * target_edge_num / expected_edges\n",
    "\n",
    "expected_edges, new_weights.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880530.4\n"
     ]
    }
   ],
   "source": [
    "def weighted_aug(graph, x, feat_drop_rate, edge_mask_rate):\n",
    "\n",
    "    target_edge_num = graph.num_edges() * (1 - edge_mask_rate)\n",
    "\n",
    "    expected_edges = graph.adj().coalesce().values().sum()\n",
    "\n",
    "    graph.adj()\n",
    "\n",
    "    print(target_edge_num)\n",
    "\n",
    "    # n_node = graph.num_nodes()\n",
    "\n",
    "    # edge_mask = mask_edge(graph, edge_mask_rate)\n",
    "    # feat = drop_feature(x, feat_drop_rate)\n",
    "\n",
    "    # src = graph.edges()[0]\n",
    "    # dst = graph.edges()[1]\n",
    "\n",
    "    # nsrc = src[edge_mask]\n",
    "    # ndst = dst[edge_mask]\n",
    "\n",
    "    # ng = dgl.graph((nsrc, ndst), num_nodes=n_node)\n",
    "    # ng = ng.add_self_loop()\n",
    "\n",
    "    # return ng, feat\n",
    "\n",
    "def drop_feature(x, drop_prob):\n",
    "    drop_mask = th.empty((x.size(1),),\n",
    "                        dtype=th.float32,\n",
    "                        device=x.device).uniform_(0, 1) < drop_prob\n",
    "    x = x.clone()\n",
    "    x[:, drop_mask] = 0\n",
    "\n",
    "    return x\n",
    "\n",
    "def mask_edge(graph, mask_prob):\n",
    "    E = graph.num_edges()\n",
    "\n",
    "    mask_rates = th.FloatTensor(np.ones(E) * mask_prob)\n",
    "    masks = th.bernoulli(1 - mask_rates)\n",
    "    mask_idx = masks.nonzero().squeeze(1)\n",
    "    return mask_idx\n",
    "\n",
    "\n",
    "weighted_aug(graph, graph.ndata['feat'], feat_drop_rate=dr, edge_mask_rate=dr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# params: 397568\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:1! (when checking argument for argument mat2 in method wrapper_mm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/u/nyw6dh/HCDM/Experiment/Fair_GRACE/test.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhcdmg2.cs.virginia.edu/u/nyw6dh/HCDM/Experiment/Fair_GRACE/test.ipynb#ch0000004vscode-remote?line=19'>20</a>\u001b[0m feat1 \u001b[39m=\u001b[39m feat1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhcdmg2.cs.virginia.edu/u/nyw6dh/HCDM/Experiment/Fair_GRACE/test.ipynb#ch0000004vscode-remote?line=20'>21</a>\u001b[0m feat2 \u001b[39m=\u001b[39m feat2\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bhcdmg2.cs.virginia.edu/u/nyw6dh/HCDM/Experiment/Fair_GRACE/test.ipynb#ch0000004vscode-remote?line=22'>23</a>\u001b[0m loss \u001b[39m=\u001b[39m model(graph1, graph2, feat1, feat2, batch_size\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhcdmg2.cs.virginia.edu/u/nyw6dh/HCDM/Experiment/Fair_GRACE/test.ipynb#ch0000004vscode-remote?line=24'>25</a>\u001b[0m \u001b[39m# UGE-R\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhcdmg2.cs.virginia.edu/u/nyw6dh/HCDM/Experiment/Fair_GRACE/test.ipynb#ch0000004vscode-remote?line=25'>26</a>\u001b[0m \u001b[39mif\u001b[39;00m debias_method \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39muge-r\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39muge-c\u001b[39m\u001b[39m'\u001b[39m]:\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_c116/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/HCDM/Experiment/Fair_GRACE/model.py:117\u001b[0m, in \u001b[0;36mGrace.forward\u001b[0;34m(self, graph1, graph2, feat1, feat2, batch_size)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, graph1, graph2, feat1, feat2, batch_size\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m    116\u001b[0m     \u001b[39m# encoding\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     h1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(graph1, feat1)\n\u001b[1;32m    118\u001b[0m     h2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(graph2, feat2)\n\u001b[1;32m    120\u001b[0m     \u001b[39m# projection\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_c116/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/HCDM/Experiment/Fair_GRACE/model.py:25\u001b[0m, in \u001b[0;36mGCN.forward\u001b[0;34m(self, graph, feat)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, graph, feat):\n\u001b[1;32m     24\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers):\n\u001b[0;32m---> 25\u001b[0m         feat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact_fn(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvs[i](graph, feat))\n\u001b[1;32m     27\u001b[0m     \u001b[39mreturn\u001b[39;00m feat\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_c116/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_c116/lib/python3.10/site-packages/dgl/nn/pytorch/conv/graphconv.py:431\u001b[0m, in \u001b[0;36mGraphConv.forward\u001b[0;34m(self, graph, feat, weight, edge_weight)\u001b[0m\n\u001b[1;32m    429\u001b[0m     rst \u001b[39m=\u001b[39m graph\u001b[39m.\u001b[39mdstdata[\u001b[39m'\u001b[39m\u001b[39mh\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    430\u001b[0m     \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 431\u001b[0m         rst \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39;49mmatmul(rst, weight)\n\u001b[1;32m    433\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_norm \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mright\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mboth\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m    434\u001b[0m     degs \u001b[39m=\u001b[39m graph\u001b[39m.\u001b[39min_degrees()\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mclamp(\u001b[39mmin\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:1! (when checking argument for argument mat2 in method wrapper_mm)"
     ]
    }
   ],
   "source": [
    "import random\n",
    "dr = 0.2\n",
    "# Step 3: Create model =================================================================== #\n",
    "model = Grace(in_dim, hid_dim, out_dim, num_layers, act_fn, temp)\n",
    "model = model.to(args.device)\n",
    "print(f'# params: {count_parameters(model)}')\n",
    "\n",
    "optimizer = th.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "# Step 4: Training =======================================================================\n",
    "for epoch in range(args.epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if debias_method in ['uge-w', 'uge-c']:\n",
    "        graph1, feat1 = weighted_aug(graph, graph.ndata['feat'], feat_drop_rate=dr, edge_mask_rate=dr)\n",
    "        graph2, feat2 = weighted_aug(graph, graph.ndata['feat'], feat_drop_rate=dr, edge_mask_rate=dr)\n",
    "    else:\n",
    "        graph1, feat1 = aug(graph, graph.ndata['feat'], feat_drop_rate=dr, edge_mask_rate=dr)\n",
    "        graph2, feat2 = aug(graph, graph.ndata['feat'], feat_drop_rate=dr, edge_mask_rate=dr)\n",
    "\n",
    "    graph1 = graph1\n",
    "    graph2 = graph2\n",
    "\n",
    "    feat1 = feat1\n",
    "    feat2 = feat2\n",
    "\n",
    "    loss = model(graph1, graph2, feat1, feat2, batch_size=1000, device=args.device)\n",
    "    \n",
    "    # UGE-R\n",
    "    if debias_method in ['uge-r', 'uge-c']:\n",
    "        h1 = model.encoder(graph1, feat1)\n",
    "        h2 = model.encoder(graph2, feat2)\n",
    "        regu_loss = 0\n",
    "        scr_groups = random.sample(list(attr_comb_groups_map.keys()), 100)  \n",
    "        dst_groups = random.sample(list(attr_comb_groups_map.keys()), 100)\n",
    "        nobias_scr_groups = [map_tuple(group, non_sens_attr_idx) for group in scr_groups]\n",
    "        nobias_dst_groups = [map_tuple(group, non_sens_attr_idx) for group in dst_groups]\n",
    "\n",
    "        for group_idx in range(len(scr_groups)):\n",
    "            for view in [h1, h2]:\n",
    "                scr_group_nodes = attr_comb_groups_map[scr_groups[group_idx]]\n",
    "                dsc_group_nodes = attr_comb_groups_map[dst_groups[group_idx]]\n",
    "                \n",
    "                scr_node_embs = view[scr_group_nodes]\n",
    "                dsc_node_embs = view[dsc_group_nodes]\n",
    "                aver_score = mem_eff_matmul_mean(scr_node_embs, dsc_node_embs.T)\n",
    "\n",
    "                nobias_scr_group_nodes = nobias_attr_comb_groups_map[nobias_scr_groups[group_idx]]\n",
    "                nobias_dsc_group_nodes = nobias_attr_comb_groups_map[nobias_dst_groups[group_idx]]\n",
    "                nobias_scr_node_embs = view[nobias_scr_group_nodes]\n",
    "                nobias_dsc_node_embs = view[nobias_dsc_group_nodes]\n",
    "                nobias_aver_score = mem_eff_matmul_mean(nobias_scr_node_embs, nobias_dsc_node_embs.T)\n",
    "\n",
    "                regu_loss += th.square(aver_score - nobias_aver_score)\n",
    "            \n",
    "        print(f\"Epoch={epoch:03d}, loss: {loss.item():.2f}, regu_loss: {regu_loss.item():.2f}\")\n",
    "\n",
    "        loss += args.reg_weight * regu_loss / 1\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f'Epoch={epoch:03d}, loss={loss.item():.4f}')\n",
    "\n",
    "# Step 5: Linear evaluation ============================================================== #\n",
    "print(\"=== Final ===\")\n",
    "\n",
    "graph = graph.add_self_loop()\n",
    "graph = graph.to(args.device)\n",
    "embeds = model.get_embedding(graph, graph.ndata['feat'].to(args.device))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data ...\n",
      "Unbiasedness evaluation (predicting attribute)\n",
      "-- micro-f1 when predicting gender: 0.5875\n",
      "-- micro-f1 when predicting age: 0.27692307692307694\n",
      "-- micro-f1 when predicting occupation: 0.045192307692307684\n",
      "Utility evaluation (link prediction)\n",
      "-- ndcg of link prediction: 0.27292922381612544\n"
     ]
    }
   ],
   "source": [
    "from eval import label_classification, eval_unbiasedness_movielens\n",
    "'''Evaluation Embeddings  '''\n",
    "# label_classification(embeds, graph.ndata['label'], graph.ndata['train_mask'], graph.ndata['test_mask'], split=args.split)\n",
    "res = eval_unbiasedness_movielens('movie', embeds.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unbiasedness': {'gender': 0.5971153846153846,\n",
       "  'age': 0.27884615384615385,\n",
       "  'region': 0.0,\n",
       "  'occupation': 0.058653846153846154},\n",
       " 'utility': 0.09987926919632206}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09987926919632206"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['utility']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data ...\n",
      "Unbiasedness evaluation (predicting attribute)\n",
      "-- micro-f1 when predicting gender: 0.525\n",
      "-- micro-f1 when predicting age: 0.15865384615384615\n",
      "-- micro-f1 when predicting occupation: 0.04807692307692308\n",
      "Utility evaluation (link prediction)\n",
      "-- ndcg of link prediction: 0.019901697480936703\n"
     ]
    }
   ],
   "source": [
    "res = eval_unbiasedness_movielens('movie', th.randn_like(embeds).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.join('../..'))\n",
    "import Utils.Export as Export\n",
    "\n",
    "results = {\n",
    "  \"dataname\": args.dataname,\n",
    "  \"epochs\": args.epochs,\n",
    "  \"debias_method\": \"random\",\n",
    "  \"debias_attr\": args.debias_attr,\n",
    "  \"reg_weight\": args.reg_weight,\n",
    "  \"temp\": args.temp,\n",
    "  \"der1\": args.der1,\n",
    "  \"der2\": args.der2,\n",
    "  \"dfr1\": args.dfr1,\n",
    "  \"dfr2\": args.dfr2,\n",
    "  \"gender_f1m\": res['unbiasedness']['gender'],\n",
    "  \"age_f1m\": res['unbiasedness']['age'],\n",
    "  \"occupation_f1m\": res['unbiasedness']['occupation'],\n",
    "  \"link_ndcg\": res['utility'],\n",
    "}\n",
    "\n",
    "Export.saveData('./results.csv', results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('pytorch_c116')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ace00f8df87249d7fb913fbec74912fd8ad566274bc64c0a2570c224c3461cb4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
