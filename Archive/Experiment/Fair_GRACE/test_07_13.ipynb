{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating DGL graph...\n",
      "Finished data loading and preprocessing.\n",
      "  NumNodes: 66569\n",
      "  NumEdges: 1100663\n",
      "  NumFeats: 262\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from model import Grace\n",
    "from aug import aug\n",
    "from dataset import load\n",
    "\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "\n",
    "from eval import label_classification, eval_unbiasedness_movielens\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum([np.prod(p.size()) for p in model.parameters() if p.requires_grad])\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataname', type=str, default='pokec-n')\n",
    "parser.add_argument('--gpu', type=int, default=2)\n",
    "parser.add_argument('--split', type=str, default='random')\n",
    "parser.add_argument('--debias_method', type=str, default='uge-r', choices=['uge-r', 'uge-w', 'uge-c', 'none'], help='debiasing method to apply')\n",
    "parser.add_argument('--debias_attr', type=str, default='age', help='sensitive attribute to be debiased')\n",
    "parser.add_argument('--reg_weight', type=float, default=0.2, help='weight for the regularization based debiasing term')  \n",
    "\n",
    "parser.add_argument('--epochs', type=int, default=100, help='Number of training periods.')\n",
    "parser.add_argument('--lr', type=float, default=0.001, help='Learning rate.')\n",
    "parser.add_argument('--wd', type=float, default=1e-5, help='Weight decay.')\n",
    "parser.add_argument('--temp', type=float, default=1.0, help='Temperature.')\n",
    "\n",
    "parser.add_argument('--act_fn', type=str, default='relu')\n",
    "\n",
    "parser.add_argument(\"--hid_dim\", type=int, default=256, help='Hidden layer dim.')\n",
    "parser.add_argument(\"--out_dim\", type=int, default=256, help='Output layer dim.')\n",
    "\n",
    "parser.add_argument(\"--num_layers\", type=int, default=2, help='Number of GNN layers.')\n",
    "parser.add_argument('--der1', type=float, default=0.2, help='Drop edge ratio of the 1st augmentation.')\n",
    "parser.add_argument('--der2', type=float, default=0.2, help='Drop edge ratio of the 2nd augmentation.')\n",
    "parser.add_argument('--dfr1', type=float, default=0.2, help='Drop feature ratio of the 1st augmentation.')\n",
    "parser.add_argument('--dfr2', type=float, default=0.2, help='Drop feature ratio of the 2nd augmentation.')\n",
    "\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "if args.gpu != -1 and th.cuda.is_available():\n",
    "    args.device = 'cuda:{}'.format(args.gpu)\n",
    "else:\n",
    "    args.device = 'cpu'\n",
    "\n",
    "# Step 1: Load hyperparameters =================================================================== #\n",
    "lr = args.lr\n",
    "hid_dim = args.hid_dim\n",
    "out_dim = args.out_dim\n",
    "\n",
    "num_layers = args.num_layers\n",
    "act_fn = ({'relu': nn.ReLU(), 'prelu': nn.PReLU()})[args.act_fn]\n",
    "\n",
    "drop_edge_rate_1 = args.der1\n",
    "drop_edge_rate_2 = args.der2\n",
    "drop_feature_rate_1 = args.dfr1\n",
    "drop_feature_rate_2 = args.dfr2\n",
    "\n",
    "temp = args.temp\n",
    "epochs = args.epochs\n",
    "wd = args.wd\n",
    "debias_method = args.debias_method\n",
    "\n",
    "# Step 2: Prepare data =================================================================== #\n",
    "if debias_method in ['uge-w', 'uge-c']:\n",
    "    dataset = '{}_debias_{}'.format(args.dataname, args.debias_attr)\n",
    "else:\n",
    "    dataset = args.dataname\n",
    "\n",
    "graph = load(dataset)\n",
    "in_dim = graph.ndata['feat'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group finished.\n",
      "  attr_comb_group_num: 306\n",
      "  nobias_attr_comb_group_num: 306\n"
     ]
    }
   ],
   "source": [
    "from dataset import SENSITIVE_ATTR_DICT  # predefined sensitive attributes for different datasets\n",
    "from dataset import DATA_FOLDER\n",
    "import pandas as pd\n",
    "\n",
    "SENSITIVE_ATTR_DICT = {\n",
    "    'movielens': ['gender', 'occupation', 'age'],\n",
    "    'pokec': ['gender', 'region', 'AGE'],\n",
    "    'pokec-z': ['gender', 'region', 'AGE'],\n",
    "    'pokec-n': ['gender', 'region', 'AGE'],\n",
    "}\n",
    "# Group nodes\n",
    "debias_attr = args.debias_attr\n",
    "attribute_list = SENSITIVE_ATTR_DICT[args.dataname]\n",
    "\n",
    "non_sens_attr_ls = [attr for attr in attribute_list if attr!=debias_attr]\n",
    "non_sens_attr_idx = [i for i in range(len(attribute_list)) if attribute_list[i]!=debias_attr]\n",
    "\n",
    "attribute_file = '{}/{}_node_attribute.csv'.format(DATA_FOLDER, args.dataname)\n",
    "node_attributes = pd.read_csv(attribute_file)\n",
    "\n",
    "attr_comb_groups = node_attributes.groupby(attribute_list)\n",
    "nobias_comb_groups = node_attributes.groupby(non_sens_attr_ls)\n",
    "\n",
    "attr_comb_groups_map = {tuple(group[1].iloc[0]):list(group[1].index) \n",
    "                        for group in attr_comb_groups}\n",
    "nobias_attr_comb_groups_map = {tuple(group[1].iloc[0][non_sens_attr_ls]):list(group[1].index) \n",
    "                            for group in nobias_comb_groups}\n",
    "\n",
    "print ('Group finished.')\n",
    "print ('  attr_comb_group_num:', len(attr_comb_groups_map.keys()))\n",
    "print ('  nobias_attr_comb_group_num:', len(nobias_attr_comb_groups_map.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_tuple(x, index_ls):\n",
    "  return tuple([x[idx] for idx in index_ls])\n",
    "\n",
    "def mem_eff_matmul_mean(mtx1, mtx2):\n",
    "  mtx1_rows = list(mtx1.shape)[0]\n",
    "  if mtx1_rows <= 1000:\n",
    "    return th.mean(th.matmul(mtx1, mtx2))\n",
    "  else:\n",
    "    value_sum = 0\n",
    "    for i in range(mtx1_rows // 1000):\n",
    "      value_sum += th.sum(th.matmul(mtx1[i*1000:(i+1)*1000, :], mtx2))\n",
    "    if mtx1_rows % 1000 != 0:\n",
    "      value_sum += th.sum(th.matmul(mtx1[(i+1)*1000:, :], mtx2))\n",
    "    return value_sum / (list(mtx1.shape)[0] * list(mtx2.shape)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "th.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# params: 397568\n",
      "a1: 9780.63178062439\n",
      "a2: 9964.164018630981\n",
      "a3: 9966.142416000366\n",
      "a1: 185.25290489196777\n",
      "a2: 379.8694610595703\n",
      "a3: 380.86891174316406\n",
      "a1: 190.30308723449707\n",
      "a2: 376.0991096496582\n",
      "a3: 376.95765495300293\n",
      "a1: 195.05548477172852\n",
      "a2: 374.40037727355957\n",
      "a3: 375.23722648620605\n",
      "a1: 179.51512336730957\n",
      "a2: 358.4592342376709\n",
      "a3: 359.3113422393799\n",
      "a1: 189.69440460205078\n",
      "a2: 365.42463302612305\n",
      "a3: 366.1508560180664\n",
      "a1: 189.042329788208\n",
      "a2: 383.36968421936035\n",
      "a3: 384.0522766113281\n",
      "a1: 185.13917922973633\n",
      "a2: 357.84220695495605\n",
      "a3: 358.66618156433105\n",
      "a1: 164.77584838867188\n",
      "a2: 336.4825248718262\n",
      "a3: 337.33153343200684\n",
      "a1: 177.1538257598877\n",
      "a2: 353.7929058074951\n",
      "a3: 354.40540313720703\n",
      "a1: 174.62706565856934\n",
      "a2: 353.2421588897705\n",
      "a3: 354.92753982543945\n",
      "a1: 178.12728881835938\n",
      "a2: 353.9767265319824\n",
      "a3: 354.78878021240234\n",
      "a1: 178.58171463012695\n",
      "a2: 347.9902744293213\n",
      "a3: 348.6027717590332\n",
      "a1: 173.9964485168457\n",
      "a2: 346.36425971984863\n",
      "a3: 347.00584411621094\n",
      "a1: 174.2868423461914\n",
      "a2: 339.1995429992676\n",
      "a3: 339.9169445037842\n",
      "a1: 176.90587043762207\n",
      "a2: 347.79810905456543\n",
      "a3: 348.4616279602051\n",
      "a1: 179.00753021240234\n",
      "a2: 352.480411529541\n",
      "a3: 353.1172275543213\n",
      "a1: 175.35924911499023\n",
      "a2: 348.0842113494873\n",
      "a3: 348.8914966583252\n",
      "a1: 180.2058219909668\n",
      "a2: 359.6069812774658\n",
      "a3: 360.39257049560547\n",
      "a1: 178.28369140625\n",
      "a2: 379.32538986206055\n",
      "a3: 381.1056613922119\n",
      "a1: 177.89506912231445\n",
      "a2: 358.7992191314697\n",
      "a3: 359.75003242492676\n",
      "a1: 176.17321014404297\n",
      "a2: 354.8846244812012\n",
      "a3: 355.7119369506836\n",
      "a1: 174.21269416809082\n",
      "a2: 347.3012447357178\n",
      "a3: 348.2046127319336\n",
      "a1: 164.45207595825195\n",
      "a2: 338.301420211792\n",
      "a3: 341.8285846710205\n",
      "a1: 172.58501052856445\n",
      "a2: 339.2014503479004\n",
      "a3: 340.12699127197266\n",
      "a1: 161.7910861968994\n",
      "a2: 329.06532287597656\n",
      "a3: 329.87403869628906\n",
      "a1: 168.40648651123047\n",
      "a2: 326.0810375213623\n",
      "a3: 326.97224617004395\n",
      "a1: 172.09720611572266\n",
      "a2: 328.02557945251465\n",
      "a3: 328.8722038269043\n",
      "a1: 159.73377227783203\n",
      "a2: 321.2113380432129\n",
      "a3: 321.96879386901855\n",
      "a1: 158.39767456054688\n",
      "a2: 317.9202079772949\n",
      "a3: 318.62521171569824\n",
      "a1: 159.0425968170166\n",
      "a2: 319.43345069885254\n",
      "a3: 320.1284408569336\n",
      "a1: 173.71129989624023\n",
      "a2: 335.6473445892334\n",
      "a3: 336.49539947509766\n",
      "a1: 158.94150733947754\n",
      "a2: 330.2896022796631\n",
      "a3: 331.0236930847168\n",
      "a1: 163.90514373779297\n",
      "a2: 328.4573554992676\n",
      "a3: 329.362154006958\n",
      "a1: 169.93236541748047\n",
      "a2: 336.87448501586914\n",
      "a3: 338.1519317626953\n",
      "a1: 165.41528701782227\n",
      "a2: 326.662540435791\n",
      "a3: 327.3770809173584\n",
      "a1: 169.71993446350098\n",
      "a2: 343.66536140441895\n",
      "a3: 344.35081481933594\n",
      "a1: 169.73042488098145\n",
      "a2: 338.24777603149414\n",
      "a3: 338.9406204223633\n",
      "a1: 168.00713539123535\n",
      "a2: 336.5347385406494\n",
      "a3: 337.33248710632324\n",
      "a1: 162.05811500549316\n",
      "a2: 319.11540031433105\n",
      "a3: 319.9598789215088\n",
      "a1: 157.4549674987793\n",
      "a2: 325.93345642089844\n",
      "a3: 326.80749893188477\n",
      "a1: 165.7569408416748\n",
      "a2: 341.34578704833984\n",
      "a3: 342.00024604797363\n",
      "a1: 160.37368774414062\n",
      "a2: 325.927734375\n",
      "a3: 326.8165588378906\n",
      "a1: 171.99134826660156\n",
      "a2: 342.3283100128174\n",
      "a3: 343.1069850921631\n",
      "a1: 166.88966751098633\n",
      "a2: 345.54052352905273\n",
      "a3: 346.2057113647461\n",
      "a1: 173.2039451599121\n",
      "a2: 351.41706466674805\n",
      "a3: 352.12016105651855\n",
      "a1: 174.59750175476074\n",
      "a2: 349.5218753814697\n",
      "a3: 350.2483367919922\n",
      "a1: 178.08151245117188\n",
      "a2: 346.57931327819824\n",
      "a3: 347.4442958831787\n",
      "a1: 168.8244342803955\n",
      "a2: 338.8397693634033\n",
      "a3: 339.7033214569092\n",
      "a1: 171.92506790161133\n",
      "a2: 342.78368949890137\n",
      "a3: 343.5180187225342\n",
      "a1: 170.15862464904785\n",
      "a2: 339.7510051727295\n",
      "a3: 340.7435417175293\n",
      "a1: 168.72072219848633\n",
      "a2: 339.4126892089844\n",
      "a3: 340.1196002960205\n",
      "a1: 170.19915580749512\n",
      "a2: 337.78905868530273\n",
      "a3: 338.53793144226074\n",
      "a1: 166.94116592407227\n",
      "a2: 337.9209041595459\n",
      "a3: 338.6070728302002\n",
      "a1: 171.27227783203125\n",
      "a2: 343.16062927246094\n",
      "a3: 343.90711784362793\n",
      "a1: 171.0951328277588\n",
      "a2: 345.7057476043701\n",
      "a3: 346.4670181274414\n",
      "a1: 174.04508590698242\n",
      "a2: 348.7834930419922\n",
      "a3: 349.4532108306885\n",
      "a1: 173.14958572387695\n",
      "a2: 343.39261054992676\n",
      "a3: 344.1908359527588\n",
      "a1: 175.29845237731934\n",
      "a2: 348.9072322845459\n",
      "a3: 349.5607376098633\n",
      "a1: 184.68546867370605\n",
      "a2: 353.98101806640625\n",
      "a3: 354.8440933227539\n",
      "a1: 172.58381843566895\n",
      "a2: 348.76275062561035\n",
      "a3: 349.4873046875\n",
      "a1: 172.2097396850586\n",
      "a2: 346.4324474334717\n",
      "a3: 347.2151756286621\n",
      "a1: 164.7019386291504\n",
      "a2: 337.116003036499\n",
      "a3: 337.9840850830078\n",
      "a1: 166.01228713989258\n",
      "a2: 324.95665550231934\n",
      "a3: 325.8202075958252\n",
      "a1: 169.1305637359619\n",
      "a2: 327.5609016418457\n",
      "a3: 328.4268379211426\n",
      "a1: 156.72683715820312\n",
      "a2: 315.1669502258301\n",
      "a3: 315.8531188964844\n",
      "a1: 95.46732902526855\n",
      "a2: 182.6941967010498\n",
      "a3: 183.35723876953125\n",
      "a1: 159.07788276672363\n",
      "a2: 330.82008361816406\n",
      "a3: 331.47573471069336\n",
      "a1: 159.4705581665039\n",
      "a2: 330.3678035736084\n",
      "a3: 330.963134765625\n",
      "a1: 170.8667278289795\n",
      "a2: 341.8407440185547\n",
      "a3: 342.4513339996338\n",
      "a1: 169.4941520690918\n",
      "a2: 339.5111560821533\n",
      "a3: 340.26145935058594\n",
      "a1: 168.8981056213379\n",
      "a2: 338.2439613342285\n",
      "a3: 338.93465995788574\n",
      "a1: 155.23219108581543\n",
      "a2: 315.1676654815674\n",
      "a3: 315.77348709106445\n",
      "a1: 165.9986972808838\n",
      "a2: 322.48830795288086\n",
      "a3: 323.23265075683594\n",
      "a1: 170.04990577697754\n",
      "a2: 339.3514156341553\n",
      "a3: 340.059757232666\n",
      "a1: 170.36867141723633\n",
      "a2: 337.94498443603516\n",
      "a3: 338.623046875\n",
      "a1: 170.46475410461426\n",
      "a2: 342.5431251525879\n",
      "a3: 343.28508377075195\n",
      "a1: 174.3772029876709\n",
      "a2: 349.41577911376953\n",
      "a3: 350.0385284423828\n",
      "a1: 174.13091659545898\n",
      "a2: 348.83999824523926\n",
      "a3: 349.4887351989746\n",
      "a1: 169.3401336669922\n",
      "a2: 345.9186553955078\n",
      "a3: 346.5135097503662\n",
      "a1: 174.02410507202148\n",
      "a2: 346.13752365112305\n",
      "a3: 346.7381000518799\n",
      "a1: 171.5395450592041\n",
      "a2: 347.8868007659912\n",
      "a3: 348.56152534484863\n",
      "a1: 189.94641304016113\n",
      "a2: 384.04130935668945\n",
      "a3: 384.59038734436035\n",
      "a1: 202.0740509033203\n",
      "a2: 413.43045234680176\n",
      "a3: 414.0439033508301\n",
      "a1: 193.50695610046387\n",
      "a2: 400.67172050476074\n",
      "a3: 401.3190269470215\n",
      "a1: 203.37486267089844\n",
      "a2: 404.83713150024414\n",
      "a3: 405.7931900024414\n",
      "a1: 208.50491523742676\n",
      "a2: 402.9543399810791\n",
      "a3: 403.70678901672363\n",
      "a1: 207.15689659118652\n",
      "a2: 420.4587936401367\n",
      "a3: 421.02885246276855\n",
      "a1: 202.15296745300293\n",
      "a2: 404.2937755584717\n",
      "a3: 404.9034118652344\n",
      "a1: 199.20063018798828\n",
      "a2: 413.18345069885254\n",
      "a3: 414.0477180480957\n",
      "a1: 212.46814727783203\n",
      "a2: 419.80695724487305\n",
      "a3: 420.5338954925537\n",
      "a1: 209.39183235168457\n",
      "a2: 403.5754203796387\n",
      "a3: 404.21056747436523\n",
      "a1: 213.87481689453125\n",
      "a2: 420.91965675354004\n",
      "a3: 421.4775562286377\n",
      "a1: 202.2228240966797\n",
      "a2: 410.8774662017822\n",
      "a3: 411.4229679107666\n",
      "a1: 209.75136756896973\n",
      "a2: 417.92798042297363\n",
      "a3: 418.48087310791016\n",
      "a1: 198.95529747009277\n",
      "a2: 413.7599468231201\n",
      "a3: 414.42346572875977\n",
      "a1: 208.0519199371338\n",
      "a2: 420.41921615600586\n",
      "a3: 421.18120193481445\n",
      "a1: 200.38270950317383\n",
      "a2: 418.2767868041992\n",
      "a3: 418.98298263549805\n",
      "a1: 208.3725929260254\n",
      "a2: 420.7415580749512\n",
      "a3: 421.3528633117676\n",
      "a1: 212.48531341552734\n",
      "a2: 420.21775245666504\n",
      "a3: 420.849084854126\n",
      "a1: 214.80822563171387\n",
      "a2: 415.0848388671875\n",
      "a3: 415.93050956726074\n",
      "a1: 213.55199813842773\n",
      "a2: 425.28414726257324\n",
      "a3: 426.0144233703613\n",
      "a1: 205.03997802734375\n",
      "a2: 421.628475189209\n",
      "a3: 422.4517345428467\n",
      "a1: 218.55926513671875\n",
      "a2: 429.31127548217773\n",
      "a3: 429.9006462097168\n",
      "a1: 208.65440368652344\n",
      "a2: 412.52851486206055\n",
      "a3: 413.30814361572266\n",
      "a1: 218.24979782104492\n",
      "a2: 423.22325706481934\n",
      "a3: 423.7785339355469\n",
      "a1: 212.27502822875977\n",
      "a2: 425.5833625793457\n",
      "a3: 426.36752128601074\n",
      "a1: 207.03625679016113\n",
      "a2: 433.0298900604248\n",
      "a3: 433.8841438293457\n",
      "a1: 213.19818496704102\n",
      "a2: 433.81333351135254\n",
      "a3: 434.497594833374\n",
      "a1: 215.43455123901367\n",
      "a2: 425.5027770996094\n",
      "a3: 426.2504577636719\n",
      "a1: 203.53007316589355\n",
      "a2: 418.8706874847412\n",
      "a3: 419.5137023925781\n",
      "a1: 199.5549201965332\n",
      "a2: 418.4424877166748\n",
      "a3: 419.09146308898926\n",
      "a1: 207.29780197143555\n",
      "a2: 426.67627334594727\n",
      "a3: 427.46615409851074\n",
      "a1: 210.24346351623535\n",
      "a2: 416.4106845855713\n",
      "a3: 417.1772003173828\n",
      "a1: 204.18286323547363\n",
      "a2: 421.72861099243164\n",
      "a3: 422.2886562347412\n",
      "a1: 217.18645095825195\n",
      "a2: 426.663875579834\n",
      "a3: 427.4616241455078\n",
      "a1: 220.1685905456543\n",
      "a2: 423.02680015563965\n",
      "a3: 423.6109256744385\n",
      "a1: 213.6557102203369\n",
      "a2: 425.8241653442383\n",
      "a3: 426.6481399536133\n",
      "a1: 206.48646354675293\n",
      "a2: 418.51258277893066\n",
      "a3: 419.1102981567383\n",
      "a1: 210.85882186889648\n",
      "a2: 428.32136154174805\n",
      "a3: 428.88355255126953\n",
      "a1: 212.7823829650879\n",
      "a2: 426.44262313842773\n",
      "a3: 427.05750465393066\n",
      "a1: 212.44502067565918\n",
      "a2: 415.59624671936035\n",
      "a3: 416.2554740905762\n",
      "a1: 215.08359909057617\n",
      "a2: 427.25563049316406\n",
      "a3: 427.8244972229004\n",
      "a1: 204.45632934570312\n",
      "a2: 419.05832290649414\n",
      "a3: 419.7556972503662\n",
      "a1: 209.60164070129395\n",
      "a2: 414.4406318664551\n",
      "a3: 414.95609283447266\n",
      "a1: 214.89691734313965\n",
      "a2: 441.18690490722656\n",
      "a3: 441.8065547943115\n",
      "a1: 215.1343822479248\n",
      "a2: 437.3900890350342\n",
      "a3: 438.01355361938477\n",
      "a1: 234.09771919250488\n",
      "a2: 461.96651458740234\n",
      "a3: 462.4805450439453\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import model\n",
    "importlib.reload(model)\n",
    "\n",
    "import random\n",
    "dr = 0.2\n",
    "# Step 3: Create model =================================================================== #\n",
    "model = model.Grace(in_dim, hid_dim, out_dim, num_layers, act_fn, temp)\n",
    "# model = model.to(args.device)\n",
    "print(f'# params: {count_parameters(model)}')\n",
    "\n",
    "optimizer = th.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "# Step 4: Training =======================================================================\n",
    "for epoch in range(args.epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    graph1, feat1 = aug(graph, graph.ndata['feat'], feat_drop_rate=dr, edge_mask_rate=dr)\n",
    "    graph2, feat2 = aug(graph, graph.ndata['feat'], feat_drop_rate=dr, edge_mask_rate=dr)\n",
    "\n",
    "    loss = model(graph1, graph2, feat1, feat2, batch_size=1000, device=args.device)\n",
    "    \n",
    "    # UGE-R\n",
    "    if debias_method in ['uge-r', 'uge-c']:\n",
    "        h1 = model.encoder(graph1, feat1)\n",
    "        h2 = model.encoder(graph2, feat2)\n",
    "        regu_loss = 0\n",
    "        scr_groups = random.sample(list(attr_comb_groups_map.keys()), 100)  \n",
    "        dst_groups = random.sample(list(attr_comb_groups_map.keys()), 100)\n",
    "        nobias_scr_groups = [map_tuple(group, non_sens_attr_idx) for group in scr_groups]\n",
    "        nobias_dst_groups = [map_tuple(group, non_sens_attr_idx) for group in dst_groups]\n",
    "\n",
    "        for group_idx in range(len(scr_groups)):\n",
    "            for view in [h1, h2]:\n",
    "                scr_group_nodes = attr_comb_groups_map[scr_groups[group_idx]]\n",
    "                dsc_group_nodes = attr_comb_groups_map[dst_groups[group_idx]]\n",
    "                \n",
    "                scr_node_embs = view[scr_group_nodes]\n",
    "                dsc_node_embs = view[dsc_group_nodes]\n",
    "                aver_score = mem_eff_matmul_mean(scr_node_embs, dsc_node_embs.T)\n",
    "\n",
    "                nobias_scr_group_nodes = nobias_attr_comb_groups_map[nobias_scr_groups[group_idx]]\n",
    "                nobias_dsc_group_nodes = nobias_attr_comb_groups_map[nobias_dst_groups[group_idx]]\n",
    "                nobias_scr_node_embs = view[nobias_scr_group_nodes]\n",
    "                nobias_dsc_node_embs = view[nobias_dsc_group_nodes]\n",
    "                nobias_aver_score = mem_eff_matmul_mean(nobias_scr_node_embs, nobias_dsc_node_embs.T)\n",
    "\n",
    "                regu_loss += th.square(aver_score - nobias_aver_score)\n",
    "            \n",
    "        print(f\"Epoch={epoch:03d}, loss: {loss.item():.2f}, regu_loss: {regu_loss.item():.2f}\")\n",
    "\n",
    "        loss += args.reg_weight * regu_loss / 1\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f'Epoch={epoch:03d}, loss={loss.item():.4f}')\n",
    "\n",
    "# Step 5: Linear evaluation ============================================================== #\n",
    "print(\"=== Final ===\")\n",
    "\n",
    "graph = graph.add_self_loop()\n",
    "graph = graph.to(args.device)\n",
    "embeds = model.get_embedding(graph, graph.ndata['feat'].to(args.device))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data ...\n",
      "Unbiasedness evaluation (predicting attribute)\n",
      "-- micro-f1 when predicting gender: 0.5875\n",
      "-- micro-f1 when predicting age: 0.27692307692307694\n",
      "-- micro-f1 when predicting occupation: 0.045192307692307684\n",
      "Utility evaluation (link prediction)\n",
      "-- ndcg of link prediction: 0.27292922381612544\n"
     ]
    }
   ],
   "source": [
    "from eval import label_classification, eval_unbiasedness_movielens\n",
    "'''Evaluation Embeddings  '''\n",
    "# label_classification(embeds, graph.ndata['label'], graph.ndata['train_mask'], graph.ndata['test_mask'], split=args.split)\n",
    "res = eval_unbiasedness_movielens('movie', embeds.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data ...\n",
      "Unbiasedness evaluation (predicting attribute)\n",
      "-- micro-f1 when predicting gender: 0.525\n",
      "-- micro-f1 when predicting age: 0.15865384615384615\n",
      "-- micro-f1 when predicting occupation: 0.04807692307692308\n",
      "Utility evaluation (link prediction)\n",
      "-- ndcg of link prediction: 0.019901697480936703\n"
     ]
    }
   ],
   "source": [
    "res = eval_unbiasedness_movielens('movie', th.randn_like(embeds).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.join('../..'))\n",
    "import Utils.Export as Export\n",
    "\n",
    "results = {\n",
    "  \"dataname\": args.dataname,\n",
    "  \"epochs\": args.epochs,\n",
    "  \"debias_method\": \"random\",\n",
    "  \"debias_attr\": args.debias_attr,\n",
    "  \"reg_weight\": args.reg_weight,\n",
    "  \"temp\": args.temp,\n",
    "  \"der1\": args.der1,\n",
    "  \"der2\": args.der2,\n",
    "  \"dfr1\": args.dfr1,\n",
    "  \"dfr2\": args.dfr2,\n",
    "  \"gender_f1m\": res['unbiasedness']['gender'],\n",
    "  \"age_f1m\": res['unbiasedness']['age'],\n",
    "  \"occupation_f1m\": res['unbiasedness']['occupation'],\n",
    "  \"link_ndcg\": res['utility'],\n",
    "}\n",
    "\n",
    "Export.saveData('./results.csv', results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('pytorch_c116')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ace00f8df87249d7fb913fbec74912fd8ad566274bc64c0a2570c224c3461cb4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
