{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Environment ====\n",
      "  torch version: 1.10.2\n",
      "  device: cpu\n",
      "  torch seed: 123\n",
      "==== Dataset: cora ====\n",
      "Loading cora dataset...\n",
      "\n",
      "[i] Dataset Summary: \n",
      "\tadj shape: [2708, 2708]\n",
      "\tfeature shape: [2708, 1433]\n",
      "\tnum labels: 7\n",
      "\tsplit seed: 123\n",
      "\ttrain|val|test: 140|500|1000\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join('../..'))\n",
    "\n",
    "################################################\n",
    "# Arguments\n",
    "################################################\n",
    "\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--seed', type=int, default=123, help='Random seed for model')\n",
    "parser.add_argument('--dataset', type=str, default='cora', help='dataset')\n",
    "\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "################################################\n",
    "# Environment\n",
    "################################################\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "if device != 'cpu':\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "print('==== Environment ====')\n",
    "print(f'  torch version: {torch.__version__}')\n",
    "print(f'  device: {device}')\n",
    "print(f'  torch seed: {args.seed}')\n",
    "\n",
    "################################################\n",
    "# Dataset\n",
    "################################################\n",
    "\n",
    "from Utils import GraphData\n",
    "\n",
    "print(f'==== Dataset: {args.dataset} ====')\n",
    "\n",
    "graph = GraphData.getGraph(\"../../Datasets\", args.dataset, \"gcn\", args.seed, device)\n",
    "graph.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_adj_view(adj, p_drop):\n",
    "    # Randomly select XX% of edges\n",
    "    p = torch.full_like(adj, p_drop).float()\n",
    "    modifications = torch.bernoulli(p)\n",
    "\n",
    "    modifications = modifications * adj # Mask it to only modify when edges are present (removal only)\n",
    "\n",
    "    return adj + modifications - (2 * adj * modifications) # XOR\n",
    "\n",
    "generate_adj_view(graph.adj, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(36456.)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_feat_view(feat: torch.tensor, p_drop):\n",
    "    # Randomly select XX% of features\n",
    "    p = torch.full([feat.shape[1]], p_drop).float()\n",
    "    target_feats = (torch.bernoulli(p) == 1).nonzero().squeeze()\n",
    "\n",
    "    return feat.index_fill(0, target_feats, 0)\n",
    "\n",
    "generate_feat_view(graph.features, 0.5).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_view(g, p_edge, p_feat):\n",
    "    return {\n",
    "        \"adj\": generate_adj_view(g.adj, p_edge),\n",
    "        \"features\": generate_feat_view(g.features, p_feat)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def sim(z1: torch.Tensor, z2: torch.Tensor):\n",
    "    z1 = F.normalize(z1)\n",
    "    z2 = F.normalize(z2)\n",
    "    return torch.mm(z1, z2.t())\n",
    "\n",
    "def s_loss(z1: torch.Tensor, z2: torch.Tensor):\n",
    "    f = lambda x: torch.exp(x / 0.4)\n",
    "    refl_sim = f(sim(z1, z1))\n",
    "    between_sim = f(sim(z1, z2))\n",
    "\n",
    "    return -torch.log(\n",
    "            between_sim.diag()\n",
    "            / (refl_sim.sum(1) + between_sim.sum(1) - refl_sim.diag()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.59684944152832\n",
      "8.578678131103516\n",
      "8.525972366333008\n",
      "8.434473991394043\n",
      "8.363480567932129\n",
      "8.30350112915039\n",
      "8.25337028503418\n",
      "8.222042083740234\n",
      "8.182612419128418\n",
      "8.148009300231934\n",
      "8.123971939086914\n",
      "8.098261833190918\n",
      "8.079007148742676\n",
      "8.061497688293457\n",
      "8.036906242370605\n",
      "8.029257774353027\n",
      "8.006060600280762\n",
      "7.982293605804443\n",
      "7.970405101776123\n",
      "7.964942455291748\n",
      "7.930498123168945\n",
      "7.9111456871032715\n",
      "7.899277210235596\n",
      "7.879704475402832\n",
      "7.86409854888916\n",
      "7.840716361999512\n",
      "7.820860862731934\n",
      "7.807607173919678\n",
      "7.804925441741943\n",
      "7.781295299530029\n",
      "7.763625144958496\n",
      "7.748591899871826\n",
      "7.734733581542969\n",
      "7.726871967315674\n",
      "7.707786560058594\n",
      "7.695126533508301\n",
      "7.677942752838135\n",
      "7.667926788330078\n",
      "7.658021450042725\n",
      "7.646245002746582\n",
      "7.640690803527832\n",
      "7.630488872528076\n",
      "7.614439487457275\n",
      "7.6083784103393555\n",
      "7.594449520111084\n",
      "7.582249164581299\n",
      "7.569818496704102\n",
      "7.5689826011657715\n",
      "7.5586347579956055\n",
      "7.548610210418701\n",
      "7.540104866027832\n",
      "7.527491569519043\n",
      "7.523734092712402\n",
      "7.512577533721924\n",
      "7.501918315887451\n",
      "7.493704795837402\n",
      "7.488161563873291\n",
      "7.478519916534424\n",
      "7.465873718261719\n",
      "7.459904193878174\n",
      "7.456214904785156\n",
      "7.453650951385498\n",
      "7.4448933601379395\n",
      "7.4359025955200195\n",
      "7.431493282318115\n",
      "7.425405979156494\n",
      "7.420086860656738\n",
      "7.411316871643066\n",
      "7.4077863693237305\n",
      "7.401984691619873\n",
      "7.395407676696777\n",
      "7.389358997344971\n",
      "7.382239818572998\n",
      "7.379253387451172\n",
      "7.368808746337891\n",
      "7.369907855987549\n",
      "7.357354164123535\n",
      "7.353902339935303\n",
      "7.347998142242432\n",
      "7.344207286834717\n",
      "7.334812164306641\n",
      "7.336968898773193\n",
      "7.327667713165283\n",
      "7.323540687561035\n",
      "7.317746162414551\n",
      "7.314882755279541\n",
      "7.308211326599121\n",
      "7.307687759399414\n",
      "7.310140132904053\n",
      "7.303606986999512\n",
      "7.300965309143066\n",
      "7.300260543823242\n",
      "7.294139862060547\n",
      "7.295016288757324\n",
      "7.292027473449707\n",
      "7.292582988739014\n",
      "7.293517589569092\n",
      "7.289359092712402\n",
      "7.281904697418213\n",
      "7.28549861907959\n",
      "7.282063007354736\n",
      "7.2799072265625\n",
      "7.2776265144348145\n",
      "7.280494689941406\n",
      "7.2778401374816895\n",
      "7.277103424072266\n",
      "7.275483131408691\n",
      "7.273333549499512\n",
      "7.272841930389404\n",
      "7.272834777832031\n",
      "7.270502090454102\n",
      "7.2689032554626465\n",
      "7.271981239318848\n",
      "7.268359184265137\n",
      "7.266809463500977\n",
      "7.270702362060547\n",
      "7.270329475402832\n",
      "7.266207218170166\n",
      "7.262419700622559\n",
      "7.2646403312683105\n",
      "7.263128280639648\n",
      "7.2652082443237305\n",
      "7.263490200042725\n",
      "7.264568328857422\n",
      "7.261888027191162\n",
      "7.26194953918457\n",
      "7.259429454803467\n",
      "7.259056091308594\n",
      "7.259627342224121\n",
      "7.259087562561035\n",
      "7.2577362060546875\n",
      "7.260390758514404\n",
      "7.2560954093933105\n",
      "7.257682800292969\n",
      "7.254754543304443\n",
      "7.256326675415039\n",
      "7.2559638023376465\n",
      "7.258172988891602\n",
      "7.25534725189209\n",
      "7.2551727294921875\n",
      "7.254636287689209\n",
      "7.253911972045898\n",
      "7.2520036697387695\n",
      "7.252345561981201\n",
      "7.253404140472412\n",
      "7.253644943237305\n",
      "7.253488063812256\n",
      "7.252197742462158\n",
      "7.250672817230225\n",
      "7.248902797698975\n",
      "7.25021505355835\n",
      "7.250408172607422\n",
      "7.24973726272583\n",
      "7.246240139007568\n",
      "7.247350215911865\n",
      "7.246288299560547\n",
      "7.2502923011779785\n",
      "7.246678829193115\n",
      "7.246974945068359\n",
      "7.246519088745117\n",
      "7.248128890991211\n",
      "7.247008800506592\n",
      "7.249932289123535\n",
      "7.2450666427612305\n",
      "7.244265556335449\n",
      "7.245270729064941\n",
      "7.245798587799072\n",
      "7.244446277618408\n",
      "7.243958950042725\n",
      "7.244944095611572\n",
      "7.244540214538574\n",
      "7.245536804199219\n",
      "7.244453430175781\n",
      "7.242435455322266\n",
      "7.241282939910889\n",
      "7.242160320281982\n",
      "7.2426838874816895\n",
      "7.239650726318359\n",
      "7.239940166473389\n",
      "7.241629123687744\n",
      "7.242577075958252\n",
      "7.239912033081055\n",
      "7.239484786987305\n",
      "7.240909576416016\n",
      "7.239927768707275\n",
      "7.240708827972412\n",
      "7.240776062011719\n",
      "7.238943576812744\n",
      "7.241115570068359\n",
      "7.237386226654053\n",
      "7.238918781280518\n",
      "7.238439083099365\n",
      "7.24116849899292\n",
      "7.237342357635498\n",
      "7.24110221862793\n",
      "7.234809398651123\n",
      "7.239120960235596\n",
      "7.239190578460693\n",
      "7.239398956298828\n",
      "7.237125873565674\n"
     ]
    }
   ],
   "source": [
    "from Models.GCN import GCN\n",
    "\n",
    "model = GCN(\n",
    "    input_features=graph.features.shape[1],\n",
    "    output_classes=graph.labels.max().item()+1,\n",
    "    hidden_layers=128,\n",
    "    device=device,\n",
    "    lr=0.05,\n",
    "    dropout=0.4,\n",
    "    weight_decay=0.00001,\n",
    "    name=f\"baseline\"\n",
    ").to(device)\n",
    "\n",
    "########################\n",
    "#region GRACE\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=model.lr, weight_decay=model.weight_decay)\n",
    "\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Generate views\n",
    "    view_A = generate_view(graph, 0.2, 0.2)\n",
    "    view_B = generate_view(graph, 0.2, 0.2)\n",
    "\n",
    "    # Obtain embeddings\n",
    "    emb_A = model(view_A[\"features\"], view_A[\"adj\"])\n",
    "    emb_B = model(view_B[\"features\"], view_B[\"adj\"])\n",
    "\n",
    "    # Contrastive objective\n",
    "    obj = (s_loss(emb_A, emb_B) + s_loss(emb_B, emb_A)).mean() * 0.5\n",
    "    \n",
    "    # Update params\n",
    "    obj.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(obj.item())\n",
    "\n",
    "#endregion\n",
    "########################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10709010064601898\n"
     ]
    }
   ],
   "source": [
    "#eval\n",
    "import Utils.Metrics as Metrics\n",
    "\n",
    "acc = Metrics.acc(model(graph.features, graph.adj).log_softmax(), graph.labels)\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pygraph')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "284a17d5edba1b82bbb8793a64a3a9f6114640b8c8687fac297a1d74e5a299a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
